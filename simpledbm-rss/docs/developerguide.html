<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.5: http://docutils.sourceforge.net/" />
<title>SimpleDBM Developers's Guide</title>
<meta name="author" content="Dibyendu Majumdar" />
<meta name="date" content="30 September 2007" />
<meta name="copyright" content="Copyright by Dibyendu Majumdar, 2005-2007" />
<style type="text/css">

/*
:Author: David Goodger (goodger@python.org)
:Id: $Id: html4css1.css 5196 2007-06-03 20:25:28Z wiemann $
:Copyright: This stylesheet has been placed in the public domain.

Default cascading style sheet for the HTML output of Docutils.

See http://docutils.sf.net/docs/howto/html-stylesheets.html for how to
customize this style sheet.
*/

/* used to remove borders from tables and images */
.borderless, table.borderless td, table.borderless th {
  border: 0 }

table.borderless td, table.borderless th {
  /* Override padding for "table.docutils td" with "! important".
     The right padding separates the table cells. */
  padding: 0 0.5em 0 0 ! important }

.first {
  /* Override more specific margin styles with "! important". */
  margin-top: 0 ! important }

.last, .with-subtitle {
  margin-bottom: 0 ! important }

.hidden {
  display: none }

a.toc-backref {
  text-decoration: none ;
  color: black }

blockquote.epigraph {
  margin: 2em 5em ; }

dl.docutils dd {
  margin-bottom: 0.5em }

/* Uncomment (and remove this text!) to get bold-faced definition list terms
dl.docutils dt {
  font-weight: bold }
*/

div.abstract {
  margin: 2em 5em }

div.abstract p.topic-title {
  font-weight: bold ;
  text-align: center }

div.admonition, div.attention, div.caution, div.danger, div.error,
div.hint, div.important, div.note, div.tip, div.warning {
  margin: 2em ;
  border: medium outset ;
  padding: 1em }

div.admonition p.admonition-title, div.hint p.admonition-title,
div.important p.admonition-title, div.note p.admonition-title,
div.tip p.admonition-title {
  font-weight: bold ;
  font-family: sans-serif }

div.attention p.admonition-title, div.caution p.admonition-title,
div.danger p.admonition-title, div.error p.admonition-title,
div.warning p.admonition-title {
  color: red ;
  font-weight: bold ;
  font-family: sans-serif }

/* Uncomment (and remove this text!) to get reduced vertical space in
   compound paragraphs.
div.compound .compound-first, div.compound .compound-middle {
  margin-bottom: 0.5em }

div.compound .compound-last, div.compound .compound-middle {
  margin-top: 0.5em }
*/

div.dedication {
  margin: 2em 5em ;
  text-align: center ;
  font-style: italic }

div.dedication p.topic-title {
  font-weight: bold ;
  font-style: normal }

div.figure {
  margin-left: 2em ;
  margin-right: 2em }

div.footer, div.header {
  clear: both;
  font-size: smaller }

div.line-block {
  display: block ;
  margin-top: 1em ;
  margin-bottom: 1em }

div.line-block div.line-block {
  margin-top: 0 ;
  margin-bottom: 0 ;
  margin-left: 1.5em }

div.sidebar {
  margin: 0 0 0.5em 1em ;
  border: medium outset ;
  padding: 1em ;
  background-color: #ffffee ;
  width: 40% ;
  float: right ;
  clear: right }

div.sidebar p.rubric {
  font-family: sans-serif ;
  font-size: medium }

div.system-messages {
  margin: 5em }

div.system-messages h1 {
  color: red }

div.system-message {
  border: medium outset ;
  padding: 1em }

div.system-message p.system-message-title {
  color: red ;
  font-weight: bold }

div.topic {
  margin: 2em }

h1.section-subtitle, h2.section-subtitle, h3.section-subtitle,
h4.section-subtitle, h5.section-subtitle, h6.section-subtitle {
  margin-top: 0.4em }

h1.title {
  text-align: center }

h2.subtitle {
  text-align: center }

hr.docutils {
  width: 75% }

img.align-left {
  clear: left }

img.align-right {
  clear: right }

ol.simple, ul.simple {
  margin-bottom: 1em }

ol.arabic {
  list-style: decimal }

ol.loweralpha {
  list-style: lower-alpha }

ol.upperalpha {
  list-style: upper-alpha }

ol.lowerroman {
  list-style: lower-roman }

ol.upperroman {
  list-style: upper-roman }

p.attribution {
  text-align: right ;
  margin-left: 50% }

p.caption {
  font-style: italic }

p.credits {
  font-style: italic ;
  font-size: smaller }

p.label {
  white-space: nowrap }

p.rubric {
  font-weight: bold ;
  font-size: larger ;
  color: maroon ;
  text-align: center }

p.sidebar-title {
  font-family: sans-serif ;
  font-weight: bold ;
  font-size: larger }

p.sidebar-subtitle {
  font-family: sans-serif ;
  font-weight: bold }

p.topic-title {
  font-weight: bold }

pre.address {
  margin-bottom: 0 ;
  margin-top: 0 ;
  font-family: serif ;
  font-size: 100% }

pre.literal-block, pre.doctest-block {
  margin-left: 2em ;
  margin-right: 2em }

span.classifier {
  font-family: sans-serif ;
  font-style: oblique }

span.classifier-delimiter {
  font-family: sans-serif ;
  font-weight: bold }

span.interpreted {
  font-family: sans-serif }

span.option {
  white-space: nowrap }

span.pre {
  white-space: pre }

span.problematic {
  color: red }

span.section-subtitle {
  /* font-size relative to parent (h1..h6 element) */
  font-size: 80% }

table.citation {
  border-left: solid 1px gray;
  margin-left: 1px }

table.docinfo {
  margin: 2em 4em }

table.docutils {
  margin-top: 0.5em ;
  margin-bottom: 0.5em }

table.footnote {
  border-left: solid 1px black;
  margin-left: 1px }

table.docutils td, table.docutils th,
table.docinfo td, table.docinfo th {
  padding-left: 0.5em ;
  padding-right: 0.5em ;
  vertical-align: top }

table.docutils th.field-name, table.docinfo th.docinfo-name {
  font-weight: bold ;
  text-align: left ;
  white-space: nowrap ;
  padding-left: 0 }

h1 tt.docutils, h2 tt.docutils, h3 tt.docutils,
h4 tt.docutils, h5 tt.docutils, h6 tt.docutils {
  font-size: 100% }

ul.auto-toc {
  list-style-type: none }

</style>
</head>
<body>
<div class="document" id="simpledbm-developers-s-guide">
<h1 class="title">SimpleDBM Developers's Guide</h1>
<table class="docinfo" frame="void" rules="none">
<col class="docinfo-name" />
<col class="docinfo-content" />
<tbody valign="top">
<tr><th class="docinfo-name">Author:</th>
<td>Dibyendu Majumdar</td></tr>
<tr><th class="docinfo-name">Contact:</th>
<td><a class="first last reference external" href="mailto:dibyendu&#64;mazumdar.demon.co.uk">dibyendu&#64;mazumdar.demon.co.uk</a></td></tr>
<tr><th class="docinfo-name">Version:</th>
<td>1.0.6</td></tr>
<tr><th class="docinfo-name">Date:</th>
<td>30 September 2007</td></tr>
<tr><th class="docinfo-name">Copyright:</th>
<td>Copyright by Dibyendu Majumdar, 2005-2007</td></tr>
</tbody>
</table>
<!-- -*- coding: utf-8 -*- -->
<p>The Developer's Guide is for you if you are interested in developing
SimpleDBM as opposed to simply using it in your projects. It covers following
topics.</p>
<ul class="simple">
<li>How to obtain SimpleDBM source packages</li>
<li>How to compile and build SimpleDBM</li>
<li>Coding conventions</li>
<li>Writing test cases for SimpleDBM</li>
<li>SimpleDBM Architecture and Design</li>
<li>Internals of various SimpleDBM modules</li>
</ul>
<p>If you are user of SimpleDBM, please use the User's Manual instead of
this document.</p>
<div class="contents topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#introduction" id="id15">Introduction</a><ul>
<li><a class="reference internal" href="#overview" id="id16">Overview</a></li>
<li><a class="reference internal" href="#technology" id="id17">Technology</a><ul>
<li><a class="reference internal" href="#third-party-libraries" id="id18">Third party libraries</a></li>
<li><a class="reference internal" href="#obtaining-simpledbm" id="id19">Obtaining SimpleDBM</a></li>
<li><a class="reference internal" href="#svn-urls" id="id20">SVN URLs</a></li>
<li><a class="reference internal" href="#pre-requisites" id="id21">Pre-requisites</a></li>
<li><a class="reference internal" href="#instructions-for-eclipse" id="id22">Instructions for Eclipse</a></li>
<li><a class="reference internal" href="#maven-commands" id="id23">Maven commands</a></li>
<li><a class="reference internal" href="#test-code-coverage" id="id24">Test Code Coverage</a></li>
<li><a class="reference internal" href="#installing-clover-plug-in-in-eclipse" id="id25">Installing Clover plug-in in Eclipse</a></li>
<li><a class="reference internal" href="#clover-support-in-maven-builds" id="id26">Clover support in Maven builds</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#coding-and-design-principles" id="id27">Coding and Design Principles</a><ul>
<li><a class="reference internal" href="#modular-design" id="id28">Modular design</a></li>
<li><a class="reference internal" href="#documentation" id="id29">Documentation</a></li>
<li><a class="reference internal" href="#java-coding-standards" id="id30">Java coding standards</a></li>
<li><a class="reference internal" href="#test-cases" id="id31">Test Cases</a></li>
<li><a class="reference internal" href="#release-schedule" id="id32">Release schedule</a></li>
</ul>
</li>
<li><a class="reference internal" href="#data-manager-rss-components" id="id33">Data Manager/RSS Components</a></li>
<li><a class="reference internal" href="#object-registry" id="id34">Object Registry</a><ul>
<li><a class="reference internal" href="#id1" id="id35">Overview</a></li>
<li><a class="reference internal" href="#registering-a-class" id="id36">Registering a class</a></li>
<li><a class="reference internal" href="#registering-singletons" id="id37">Registering Singletons</a></li>
<li><a class="reference internal" href="#object-registry-aware-classes" id="id38">Object Registry aware classes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#storage-manager" id="id39">Storage Manager</a><ul>
<li><a class="reference internal" href="#id2" id="id40">Overview</a></li>
<li><a class="reference internal" href="#storage-containers" id="id41">Storage Containers</a></li>
<li><a class="reference internal" href="#storage-container-registry" id="id42">Storage Container Registry</a></li>
<li><a class="reference internal" href="#storable-interface-and-object-serialization" id="id43">Storable Interface and Object serialization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#latch-manager" id="id44">Latch Manager</a><ul>
<li><a class="reference internal" href="#id3" id="id45">Overview</a></li>
<li><a class="reference internal" href="#latch-modes" id="id46">Latch modes</a></li>
<li><a class="reference internal" href="#implementation-and-performance-notes" id="id47">Implementation and Performance Notes</a></li>
<li><a class="reference internal" href="#obtaining-a-latch-instance" id="id48">Obtaining a latch instance</a></li>
</ul>
</li>
<li><a class="reference internal" href="#log-manager" id="id49">Log Manager</a><ul>
<li><a class="reference internal" href="#id4" id="id50">Overview</a></li>
<li><a class="reference internal" href="#write-ahead-log-wal-protocol" id="id51">Write Ahead Log (WAL) Protocol</a></li>
<li><a class="reference internal" href="#advantages-of-wal" id="id52">Advantages of WAL</a></li>
<li><a class="reference internal" href="#usage-notes" id="id53">Usage Notes</a></li>
<li><a class="reference internal" href="#simpledbm-implementation-of-the-log" id="id54">SimpleDBM Implementation of the Log</a></li>
<li><a class="reference internal" href="#limitations-of-current-design" id="id55">Limitations of current design</a></li>
<li><a class="reference internal" href="#operations" id="id56">Operations</a><ul>
<li><a class="reference internal" href="#creating-a-new-log-instance" id="id57">Creating a new Log Instance</a></li>
<li><a class="reference internal" href="#opening-a-log-instance" id="id58">Opening a log instance</a></li>
<li><a class="reference internal" href="#inserting-new-log-records" id="id59">Inserting new log records</a></li>
<li><a class="reference internal" href="#flushing-the-log" id="id60">Flushing the Log</a></li>
<li><a class="reference internal" href="#reading-log-records" id="id61">Reading Log records</a></li>
<li><a class="reference internal" href="#checkpoint-records" id="id62">Checkpoint Records</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#lock-manager" id="id63">Lock Manager</a><ul>
<li><a class="reference internal" href="#id5" id="id64">Introduction</a></li>
<li><a class="reference internal" href="#locking-basics" id="id65">Locking Basics</a></li>
<li><a class="reference internal" href="#two-phase-locking-and-repeatable-read-isolation-level" id="id66">Two-Phase Locking and Repeatable Read Isolation Level</a></li>
<li><a class="reference internal" href="#read-committed-isolation-level" id="id67">Read Committed Isolation Level</a></li>
<li><a class="reference internal" href="#serializable-isolation-level" id="id68">Serializable Isolation Level</a></li>
<li><a class="reference internal" href="#design-choices" id="id69">Design choices</a></li>
<li><a class="reference internal" href="#lock-modes" id="id70">Lock Modes</a><ul>
<li><a class="reference internal" href="#lock-compatibility-matrix" id="id71">Lock Compatibility Matrix</a></li>
<li><a class="reference internal" href="#lock-conversions" id="id72">Lock Conversions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id6" id="id73">Operations</a><ul>
<li><a class="reference internal" href="#obtaining-an-instance-of-lock-manager" id="id74">Obtaining an instance of Lock Manager</a></li>
<li><a class="reference internal" href="#lockable-objects" id="id75">Lockable objects</a></li>
<li><a class="reference internal" href="#lock-owners" id="id76">Lock Owners</a></li>
<li><a class="reference internal" href="#lock-durations" id="id77">Lock Durations</a></li>
<li><a class="reference internal" href="#acquiring-and-releasing-locks" id="id78">Acquiring and releasing locks</a></li>
<li><a class="reference internal" href="#limitations-in-current-implementation" id="id79">Limitations in current implementation</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#page-manager" id="id80">Page Manager</a><ul>
<li><a class="reference internal" href="#overview-of-page-manager-module" id="id81">Overview of Page Manager module</a></li>
<li><a class="reference internal" href="#interactions-with-other-modules" id="id82">Interactions with other modules</a></li>
<li><a class="reference internal" href="#page-class" id="id83">Page class</a><ul>
<li><a class="reference internal" href="#page-size-and-implementation-of-storable-interface" id="id84">Page Size and implementation of Storable interface</a></li>
<li><a class="reference internal" href="#how-various-page-types-are-managed" id="id85">How various Page types are managed</a></li>
<li><a class="reference internal" href="#page-factory" id="id86">Page Factory</a></li>
<li><a class="reference internal" href="#storing-and-retrieving-pages" id="id87">Storing and retrieving Pages</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#buffer-manager" id="id88">Buffer Manager</a><ul>
<li><a class="reference internal" href="#id7" id="id89">Overview</a></li>
<li><a class="reference internal" href="#id8" id="id90">Interactions with other modules</a></li>
<li><a class="reference internal" href="#id9" id="id91">Operations</a><ul>
<li><a class="reference internal" href="#creating-a-buffer-manager-instance" id="id92">Creating a Buffer Manager instance</a></li>
<li><a class="reference internal" href="#fixing-pages-in-the-buffer-pool" id="id93">Fixing Pages in the Buffer Pool</a></li>
<li><a class="reference internal" href="#modifying-page-contents" id="id94">Modifying page contents</a></li>
<li><a class="reference internal" href="#changing-lock-modes" id="id95">Changing lock modes</a></li>
<li><a class="reference internal" href="#unfixing-a-page" id="id96">Unfixing a Page</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#transaction-manager" id="id97">Transaction Manager</a><ul>
<li><a class="reference internal" href="#id10" id="id98">Introduction</a></li>
<li><a class="reference internal" href="#overiew" id="id99">Overiew</a></li>
<li><a class="reference internal" href="#what-is-aries" id="id100">What is ARIES?</a></li>
<li><a class="reference internal" href="#aries-an-overview" id="id101">ARIES - An Overview</a></li>
<li><a class="reference internal" href="#features-of-aries" id="id102">Features of ARIES</a></li>
<li><a class="reference internal" href="#transactions-and-locks" id="id103">Transactions and Locks</a></li>
<li><a class="reference internal" href="#transactions-and-modules" id="id104">Transactions and Modules</a></li>
<li><a class="reference internal" href="#transactions-and-log-records" id="id105">Transactions and Log records</a></li>
<li><a class="reference internal" href="#the-loggable-hierarchy" id="id106">The Loggable hierarchy</a><ul>
<li><a class="reference internal" href="#loggable-hierarchy" id="id107">Loggable Hierarchy</a></li>
<li><a class="reference internal" href="#transaction-manager-internal-log-records" id="id108">Transaction Manager Internal Log Records</a></li>
<li><a class="reference internal" href="#redoable" id="id109">Redoable</a></li>
<li><a class="reference internal" href="#baseloggable-abstract-class" id="id110">BaseLoggable abstract class</a></li>
<li><a class="reference internal" href="#pageformatoperation" id="id111">PageFormatOperation</a></li>
<li><a class="reference internal" href="#multipageredo" id="id112">MultiPageRedo</a></li>
<li><a class="reference internal" href="#undoable" id="id113">Undoable</a></li>
<li><a class="reference internal" href="#physical-undos" id="id114">Physical Undos</a></li>
<li><a class="reference internal" href="#singlepagelogicalundos" id="id115">SinglePageLogicalUndos</a></li>
<li><a class="reference internal" href="#logicalundos" id="id116">LogicalUndos</a></li>
<li><a class="reference internal" href="#comments-about-implementing-undo-operations" id="id117">Comments about implementing undo operations</a></li>
<li><a class="reference internal" href="#compensation-records" id="id118">Compensation records</a></li>
<li><a class="reference internal" href="#nontransactionrelatedoperations" id="id119">NonTransactionRelatedOperations</a></li>
<li><a class="reference internal" href="#postcommitactions" id="id120">PostCommitActions</a></li>
<li><a class="reference internal" href="#containerdeleteoperations" id="id121">ContainerDeleteOperations</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#space-manager" id="id122">Space Manager</a><ul>
<li><a class="reference internal" href="#id11" id="id123">Introduction</a></li>
<li><a class="reference internal" href="#comparison-with-storage-manager-module" id="id124">Comparison with Storage Manager module</a></li>
<li><a class="reference internal" href="#id12" id="id125">Operations</a><ul>
<li><a class="reference internal" href="#obtaining-an-instance-of-spacemgr" id="id126">Obtaining an instance of SpaceMgr</a></li>
<li><a class="reference internal" href="#creating-a-container" id="id127">Creating a Container</a></li>
<li><a class="reference internal" href="#extending-a-container" id="id128">Extending a Container</a></li>
<li><a class="reference internal" href="#deleting-a-container" id="id129">Deleting a container</a></li>
<li><a class="reference internal" href="#searching-for-free-space" id="id130">Searching for free space</a></li>
<li><a class="reference internal" href="#updating-space-information" id="id131">Updating space information</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#slotted-page-manager" id="id132">Slotted Page Manager</a><ul>
<li><a class="reference internal" href="#id13" id="id133">Introduction</a></li>
<li><a class="reference internal" href="#structure-of-slotted-page" id="id134">Structure of Slotted Page</a></li>
<li><a class="reference internal" href="#obtaining-instances-of-slotted-page" id="id135">Obtaining instances of Slotted Page</a></li>
<li><a class="reference internal" href="#inserting-or-updating-records" id="id136">Inserting or updating records</a></li>
<li><a class="reference internal" href="#deleting-records" id="id137">Deleting records</a></li>
<li><a class="reference internal" href="#accessing-records" id="id138">Accessing records</a></li>
<li><a class="reference internal" href="#miscellaneous-operations" id="id139">Miscellaneous operations</a></li>
</ul>
</li>
<li><a class="reference internal" href="#index-manager" id="id140">Index Manager</a><ul>
<li><a class="reference internal" href="#id14" id="id141">Overview</a></li>
<li><a class="reference internal" href="#structure-of-the-b-link-tree" id="id142">Structure of the B-link Tree</a></li>
<li><a class="reference internal" href="#structure-of-nodes" id="id143">Structure of Nodes</a><ul>
<li><a class="reference internal" href="#leaf-nodes" id="id144">Leaf Nodes</a></li>
<li><a class="reference internal" href="#index-nodes" id="id145">Index Nodes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#key-differences-from-published-algorithm" id="id146">Key Differences from published algorithm</a><ul>
<li><a class="reference internal" href="#page-split-operation" id="id147">Page Split operation</a></li>
<li><a class="reference internal" href="#merge-operation" id="id148">Merge Operation</a></li>
<li><a class="reference internal" href="#link-operation" id="id149">Link Operation</a></li>
<li><a class="reference internal" href="#unlink-operation" id="id150">Unlink Operation</a></li>
<li><a class="reference internal" href="#redistribute-keys-operation" id="id151">Redistribute Keys Operation</a></li>
<li><a class="reference internal" href="#increase-tree-height-operation" id="id152">Increase Tree Height Operation</a></li>
<li><a class="reference internal" href="#decrease-tree-height-operation" id="id153">Decrease Tree Height Operation</a></li>
<li><a class="reference internal" href="#index-scans" id="id154">Index Scans</a></li>
<li><a class="reference internal" href="#simplified-algorithm-for-scans" id="id155">Simplified Algorithm for Scans</a></li>
<li><a class="reference internal" href="#simpler-page-modification-checks" id="id156">Simpler page modification checks</a></li>
<li><a class="reference internal" href="#b-tree-index-is-a-secondary-structure" id="id157">B-Tree index is a secondary structure</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#tuple-manager" id="id158">Tuple Manager</a><ul>
<li><a class="reference internal" href="#overview-of-tuple-manager" id="id159">Overview of Tuple Manager</a></li>
<li><a class="reference internal" href="#design-decisions" id="id160">Design Decisions</a><ul>
<li><a class="reference internal" href="#tuple-inserts" id="id161">Tuple Inserts</a></li>
<li><a class="reference internal" href="#tuple-segmentation" id="id162">Tuple Segmentation</a></li>
<li><a class="reference internal" href="#tuple-deletes" id="id163">Tuple Deletes</a></li>
<li><a class="reference internal" href="#tuple-updates" id="id164">Tuple Updates</a></li>
<li><a class="reference internal" href="#space-reclamation" id="id165">Space Reclamation</a></li>
<li><a class="reference internal" href="#tuple-segment-structure" id="id166">Tuple Segment Structure</a></li>
<li><a class="reference internal" href="#free-space-information" id="id167">Free Space Information</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="introduction">
<h1><a class="toc-backref" href="#id15">Introduction</a></h1>
<div class="section" id="overview">
<h2><a class="toc-backref" href="#id16">Overview</a></h2>
<p>The goal of SimpleDBM project is to build a Relational Database
Manager in Java.</p>
<p>It is anticipated that there will be two major sub-systems in the
dbms backend. The Data Manager subsystem (Relational Storage System
or RSS in System R parlance) will be responsible for implementing
low-level stuff such as transactions, locking, buffer management,
table and index management. This is currently implemented.</p>
<p>The second major sub-system will be called SQL Manager (Relational
Data System or RDS). Its job will be to parse SQL statements,
produce optimum execution plans, and execute SQL statements. Development
of the SQL Manager sub-system has not started yet.</p>
</div>
<div class="section" id="technology">
<h2><a class="toc-backref" href="#id17">Technology</a></h2>
<p>SimpleDBM is written in Java and uses features available since version 5.0
of this language.</p>
<div class="section" id="third-party-libraries">
<h3><a class="toc-backref" href="#id18">Third party libraries</a></h3>
<p>To void license compatibility issues, and to reduce dependency on
third-party libraries, SimpleDBM makes little or no use of any
external libraries. A custom wrapper is used for logging, which uses
the Java logging API by default, but can use Log4J if available.</p>
</div>
<div class="section" id="obtaining-simpledbm">
<h3><a class="toc-backref" href="#id19">Obtaining SimpleDBM</a></h3>
<p>SimpleDBM source can be obtained from the SimpleDBM Google project
site <a class="reference external" href="http://code.google.com/p/simpledbm/">http://code.google.com/p/simpledbm/</a>. Source code is maintained in
a Subversion repository, so you will need a subversion client on
your PC.</p>
<p>The SimpleDBM SVN repository is organized as follows:</p>
<pre class="literal-block">
trunk  --+--- simpledbm-rss          This contains the core DBMS engine
         |
         +--- simpledbm-typesystem   This contains a simple typesystem
         |                           that can be used with SimpleDBM.
         |
         +--- simpledbm-database     This contains a higher level DB
         |                           API that makes life easier for
         |                           users. It uses the typesystem
         |                           component.
         |
         +--- simpledbm-samples      This contains some sample programs
                                     that demonstrate how to use SimpleDBM.
</pre>
<p>Under each of the top-level folders, there is the following structure.</p>
<pre class="literal-block">
--+--- code            This is where the source code is.
  |
  +--- docs            This folder contains documents.
  |
  +--- site            This folder contains web site contents.
</pre>
<p>Some of these folders may be empty if no content has been created.</p>
<p>In the code sub-directory, there is a top-level directory for each project.</p>
</div>
<div class="section" id="svn-urls">
<h3><a class="toc-backref" href="#id20">SVN URLs</a></h3>
<p>Here are the SVN URLs for the various SimpleDBM sub-systems.</p>
<dl class="docutils">
<dt>SimpleDBM-RSS</dt>
<dd><a class="reference external" href="http://simpledbm.googlecode.com/svn/trunk/simpledbm-rss/code/simpledbm-rss">http://simpledbm.googlecode.com/svn/trunk/simpledbm-rss/code/simpledbm-rss</a></dd>
<dt>SimpleDBM-TypeSystem</dt>
<dd><a class="reference external" href="http://simpledbm.googlecode.com/svn/trunk/simpledbm-typesystem/code/simpledbm-typesystem">http://simpledbm.googlecode.com/svn/trunk/simpledbm-typesystem/code/simpledbm-typesystem</a></dd>
<dt>SimpleDBM-Database</dt>
<dd><a class="reference external" href="http://simpledbm.googlecode.com/svn/trunk/simpledbm-database/code/simpledbm-database">http://simpledbm.googlecode.com/svn/trunk/simpledbm-database/code/simpledbm-database</a></dd>
<dt>TupleDemo sample</dt>
<dd><a class="reference external" href="http://simpledbm.googlecode.com/svn/trunk/simpledbm-samples/code/tupledemo">http://simpledbm.googlecode.com/svn/trunk/simpledbm-samples/code/tupledemo</a></dd>
<dt>B-TreeDemo sample</dt>
<dd><a class="reference external" href="http://simpledbm.googlecode.com/svn/trunk/simpledbm-samples/code/btreedemo">http://simpledbm.googlecode.com/svn/trunk/simpledbm-samples/code/btreedemo</a></dd>
</dl>
<p>If you are a committer, you need to use <tt class="docutils literal"><span class="pre">https</span></tt> instead of <tt class="docutils literal"><span class="pre">http</span></tt>.</p>
</div>
<div class="section" id="pre-requisites">
<h3><a class="toc-backref" href="#id21">Pre-requisites</a></h3>
<p>SimpleDBM uses <a class="reference external" href="http://maven.apache.org.">Maven</a> for build management. You will need to obtain a
copy of Maven 2. Install Maven and set up your PATH so that Maven can be
executed by typing the following command.</p>
<pre class="literal-block">
mvn
</pre>
<p>SimpleDBM development is done using Eclipse 3.2. You can use any IDE
of your choice, but you may need to find ways of converting the maven
projects to the format recognised by your IDE.</p>
<p>You will need a Subversion client in order to checkout the code for
SimpleDBM. The following URL can be used to download the Eclipse subclipse
plugin through the Eclipse Update Manager.</p>
<blockquote>
<a class="reference external" href="http://subclipse.tigris.org/update_1.2.x">http://subclipse.tigris.org/update_1.2.x</a></blockquote>
<p>SimpleDBM requires Java SE 5.0 or above. Java SE 6.0 is recommended.
On the Mac, Java SE 5.0 is available for Mac OS X Tiger - but I have found
that when running the test cases, this JVM often just hangs.</p>
<p>Make sure that Eclipse is setup to use J2SE 5.0 JRE, otherwise,
SimpleDBM code will not compile.</p>
</div>
<div class="section" id="instructions-for-eclipse">
<h3><a class="toc-backref" href="#id22">Instructions for Eclipse</a></h3>
<p>The following instructions are for the simpledbm-rss project.
However, the same instructions apply for the other projects, simply
change the SVN URL as appropriate.</p>
<p>1. Create a new classpath variable named <tt class="docutils literal"><span class="pre">M2_REPO</span></tt> inside
Eclipse. From the menu bar, select Window &gt; Preferences. Select the Java
&gt; Build Path &gt; Classpath Variables page. The <tt class="docutils literal"><span class="pre">M2_REPO</span></tt> variable should
contain the path to your local Maven 2 repository. Usually this is
<tt class="docutils literal"><span class="pre">&lt;Your</span> <span class="pre">Home</span> <span class="pre">Directory&gt;/.m2/repository</span></tt>.</p>
<p>2. Create a new SVN repository location in Eclipse
<a class="reference external" href="http://simpledbm.googlecode.com/svn/trunk/simpledbm-rss/code">http://simpledbm.googlecode.com/svn/trunk/simpledbm-rss/code</a>.
If you are a committer, use https instead of http.</p>
<p>3. Checkout the folder simpledbm-rss as a project in the
workspace.</p>
<ol class="arabic simple" start="4">
<li>Start a command shell. Cd to the project directory.</li>
<li>Run <tt class="docutils literal"><span class="pre">mvn</span> <span class="pre">eclipse:clean</span></tt>, followed by <tt class="docutils literal"><span class="pre">mvn</span> <span class="pre">eclipse:eclipse</span></tt>.</li>
</ol>
<p>6. Switch back to Eclipse and refresh the project. It should now
display a small J against the project showing that it is a Java project. Eclipse
is now setup to automatically rebuild SimpleDBM whenever you change any
code.</p>
</div>
<div class="section" id="maven-commands">
<h3><a class="toc-backref" href="#id23">Maven commands</a></h3>
<p>You can also compile, test and do other operations using maven commands.
The following maven commands are commonly used.</p>
<p>To run the test cases.</p>
<pre class="literal-block">
mvn test
</pre>
<p>To create the package and install it in the local repository.</p>
<pre class="literal-block">
mvn install
</pre>
</div>
<div class="section" id="test-code-coverage">
<h3><a class="toc-backref" href="#id24">Test Code Coverage</a></h3>
<p>I use Clover Code Coverage tool to analyse the coverage of unit test cases.</p>
</div>
<div class="section" id="installing-clover-plug-in-in-eclipse">
<h3><a class="toc-backref" href="#id25">Installing Clover plug-in in Eclipse</a></h3>
<p>The Clover plugin for Eclipse can be downloaded from the Clover
website <tt class="docutils literal"><span class="pre">http://www.cenqua.com/clover/</span></tt>. After
downloading, extract the zip file and place contents in your Eclipse
plugins folder. You will need to separately download and install a
license file in the top-level Clover plugin directory. Restart Eclipse
to enable Clover.</p>
<p>Open the Project Properties window, and navigate to the Clover
tab. Click Enable Clover plugin in this project. Click on the
Compilation tab. Enable Fork compiler into separate JVM. Enter the Java
5.0 JDK installation directory in the <tt class="docutils literal"><span class="pre">JDK_HOME</span></tt> field, and set the Heap
size of the compiler JVM to 64 MB.</p>
<p>In the Clover View, select SimpleDBM project, and click on the
button Toggle Compiling with Clover. Now when you build SimpleDBM or run
any of the unit tests, Clover will automatically produce coverage data.</p>
</div>
<div class="section" id="clover-support-in-maven-builds">
<h3><a class="toc-backref" href="#id26">Clover support in Maven builds</a></h3>
<p>The SimpleDBM Maven build script is already configured for
Clover. You must save the Clover license file to
<tt class="docutils literal"><span class="pre">src/test/clover/clover.license</span></tt> prior to executing mvn.</p>
<p>To build SimpleDBM with Clover enabled, and to produce a coverage
report, run:</p>
<pre class="literal-block">
mvn clover:instrument clover:clover
</pre>
<p>The report will be produced in the folder <tt class="docutils literal"><span class="pre">target/site/clover</span></tt>.</p>
</div>
</div>
</div>
<div class="section" id="coding-and-design-principles">
<h1><a class="toc-backref" href="#id27">Coding and Design Principles</a></h1>
<div class="section" id="modular-design">
<h2><a class="toc-backref" href="#id28">Modular design</a></h2>
<p>SimpleDBM is broken down into modules. Each module implements a
particular sub-system, and is contained in its own package.</p>
<p>Each module has a public API, which is specified via a set of Java
interfaces. Classes must not be used as part of the public API,
though there are a few exceptional cases.</p>
<p>To make the modules reusable and as independent of each other as
possible, the interface of a module is deliberately specified in
general terms. Where possible, direct dependence between modules is
avoided. If two modules are dependent, then the only permissible way
for one module to interact with another is to go via the public
interfaces of the respective modules. Modules are not allowed to
depend upon implementation specifics of other modules.</p>
<p>SimpleDBM uses constructor based dependency injection to link
modules. It is being designed in such a way that a third-party IoC
(Inversion of Control) container may be used to manage the
dependencies.</p>
</div>
<div class="section" id="documentation">
<h2><a class="toc-backref" href="#id29">Documentation</a></h2>
<p>Most of the design documentation for SimpleDBM is incorporated as
Javadoc comments within the source code, and in package and overview
documents. The aim is to keep the documentation as close to the
source code as possible.</p>
<p>Being an educational project, producing good documentation is high
priority.</p>
</div>
<div class="section" id="java-coding-standards">
<h2><a class="toc-backref" href="#id30">Java coding standards</a></h2>
<p>Heavy use is made of the new concurrency packages in Java 5.0. Enums
are used where appropriate. SimpleDBM does not define any Generic
classes itself, but makes liberal use of Java 5.0 Generic classes.</p>
<p>Fine grained thread locking is used to maximize concurrency. Using
coarse grained locking would have simplified the code, but would not
have provided an opportunity for exploring various techniques for
fine-grained locking. Deadlock is avoided by careful ordering of
locks.</p>
<p>Memory management is left to the Garbage Collector. Rather than
using Object pools, SimpleDBM encourages the use of short-lived
objects, on the basis that this aids the garbage collector in
reclaiming space more quickly. The aim is to keep permanently
occupied memory to a low level.</p>
<p>Checked Exceptions are used in most cases. Each module defines its
own Exception hierarchy. Exceptions are either handled or passed up
the stack - if they are ignored then this is documented in the code.
Care is taken to report Exceptions properly. All error messages are
given error codes.</p>
<p>Particular attention is paid to cleaning up of resources. To ensure
that resources are cleaned up during normal as well as exceptional
circumstances, finally blocks are used.</p>
<p>Debug messages are used liberally - and are executed conditionally
so that if debug is switched off, there is minimal impact on
performance.</p>
</div>
<div class="section" id="test-cases">
<h2><a class="toc-backref" href="#id31">Test Cases</a></h2>
<p>Each module is accompanied with JUnit test cases.</p>
</div>
<div class="section" id="release-schedule">
<h2><a class="toc-backref" href="#id32">Release schedule</a></h2>
<p>The system is designed so that each module is usable once it is
delivered. This means that although the full system has not yet been
constructed, the individual modules can be used as soon as they are
available.</p>
</div>
</div>
<div class="section" id="data-manager-rss-components">
<h1><a class="toc-backref" href="#id33">Data Manager/RSS Components</a></h1>
<p>The Data Manager/Relational Storage system consists of the
components listed in the table given below.</p>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="79%" />
</colgroup>
<tbody valign="top">
<tr><td>Module Name</td>
<td>Description</td>
</tr>
<tr><td>Logging</td>
<td>Provides a Logger implmentation that hides
implementation details. Can wrap either JDK
logging or Log4J.</td>
</tr>
<tr><td>Utility</td>
<td>Contains miscellaneous utility classes.</td>
</tr>
<tr><td>Registry</td>
<td>Provides the Object Registry, which is a
factory for creating objects based on type
code.</td>
</tr>
<tr><td>Storage
Manager</td>
<td>Povides an abstraction for input/output of
storage conainers similar to files.</td>
</tr>
<tr><td>Latch</td>
<td>Provides read/write latches that can be used
to manage concurrency.</td>
</tr>
<tr><td>Lock Manager</td>
<td>Implements a Lock Scheduler that allows
locking of arbitrary objects. Several
different lock modes are supported.</td>
</tr>
<tr><td>Page Manager</td>
<td>The Page Manager defines the page size and
provides mapping of pages to storage
containers.</td>
</tr>
<tr><td>Buffer
Manager</td>
<td>The Buffer Manager module implements the
Page Cache where recently accessed pages are
stoed temporarily.</td>
</tr>
<tr><td>Log Manager</td>
<td>The Write Ahead Log Manager is used for
recording changes made to the database for
recovery purposes.</td>
</tr>
<tr><td>Transaction
Manager</td>
<td>The Transaction Manager manages
transactions, system restart and recovery.</td>
</tr>
<tr><td>Free Space
Manager</td>
<td>The Free Space Maager is responsible for
managing free space information in storage
containers.</td>
</tr>
<tr><td>Slotted Page
Manager</td>
<td>The Slotted Page Manager provides an common
implementation of page containing multiple
records. A slot table is used to provide a
level of indirection to the records. This
allows records to be moved within the page
without affecting clients.</td>
</tr>
<tr><td>Location</td>
<td>The Location module specifices the inteface
for identifying lockable records in storage
containers.</td>
</tr>
<tr><td>Index
Manager</td>
<td>Provides efficient structures for accessing
locations based upon key values.</td>
</tr>
<tr><td>Tuple
Manager</td>
<td>Provides an implementation of tuple
containers. A tuple is defined as variable
sized blob of data that has a unique
identity within the tuple container.</td>
</tr>
<tr><td>Server</td>
<td>This brings together all the other modules
and provides overall management of the
SimpleDBM database engine.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="object-registry">
<h1><a class="toc-backref" href="#id34">Object Registry</a></h1>
<div class="section" id="id1">
<h2><a class="toc-backref" href="#id35">Overview</a></h2>
<p>In any object oriented persistence system, there has to be a
mechanism for creating objects dynamically, given some form of type
identification. SimpleDBM uses a simple Object Registry database for
this purpose. Each class that may be dynamically instantiated is
assigned a unique type code. The type code and the associated class
name is registered in the SimpleDBM Object Registry. The typecode
can subsequently be used to request an object of the specified
class.</p>
</div>
<div class="section" id="registering-a-class">
<h2><a class="toc-backref" href="#id36">Registering a class</a></h2>
<p>Before an object of a particular type can be instantiated, its class
must be registered with the Object Registry. An example of how this
is done is shown below:</p>
<pre class="literal-block">
ObjectFactory objectFactory = new ObjectFactoryImpl();
objectFactory.register(1, String.class.getName());
</pre>
<p>Above registers the <tt class="docutils literal"><span class="pre">String</span></tt> class with the Object Registry. It
assigns the type code 1 to the <tt class="docutils literal"><span class="pre">String</span></tt> class. Objects of the
registered classes may be instantiated using their type codes:</p>
<pre class="literal-block">
String t = (String) objectFactory.getInstance(1);
</pre>
<p>For a class to be eligible for registration, it must implement the
default no-argument constructor.</p>
</div>
<div class="section" id="registering-singletons">
<h2><a class="toc-backref" href="#id37">Registering Singletons</a></h2>
<p>SimpleDBM's object registry also supports registration of
singletons. Instead of the class name, simply supply an Object
instance. Example:</p>
<pre class="literal-block">
ObjectFactory objectFactory = new ObjectFactoryImpl();
objectFactory.register(1, new String(&quot;hello&quot;));
</pre>
</div>
<div class="section" id="object-registry-aware-classes">
<h2><a class="toc-backref" href="#id38">Object Registry aware classes</a></h2>
<p>Some objects may need to obtain instances of other classes. To do
this, objects of such classes need access to the Object Registry. If
a class implements the <tt class="docutils literal"><span class="pre">ObjectFactoryAware</span></tt> interface, then it
will be injected with the appropriate Object Registry object at the
time of initialisation.</p>
<p>Example:</p>
<pre class="literal-block">
class MyObject implements ObjectFactoryAware {
  ObjectFactory objectFactory;
  public void setObjectFactory(ObjectFactory factory) {
    this.objectFactory = factory;
  }
  public MyObject() {
  }
}
</pre>
</div>
</div>
<div class="section" id="storage-manager">
<h1><a class="toc-backref" href="#id39">Storage Manager</a></h1>
<div class="section" id="id2">
<h2><a class="toc-backref" href="#id40">Overview</a></h2>
<p>Database Managers typically use files to store various types of
data, such as, log files, data files, etc. However, from the
perspective of a DBMS, the concept of a file is a logical one; all
the DBMS cares about is a named storage container that supports
random positioned IO. As long as this requirement is met, it is not
important whether a container maps to a file or to some other
device.</p>
<p>The objective of this package is to provide a level of abstraction
to the rest of the DBMS so that the mapping of a container to a file
becomes an implementation artefact. If desired, containers may be
mapped to raw devices, or to segments within a file.</p>
</div>
<div class="section" id="storage-containers">
<h2><a class="toc-backref" href="#id41">Storage Containers</a></h2>
<p>A Storage Container is a named entity that supports positioned
(random) Input/Output. The default implementation maps a container
to a file, but this is an implementation detail. The rest of the
system does not need to know what the storage container maps to.</p>
<p>In SimpleDBM, each table or index maps to a single storage
container. The Write Ahead Log also uses storage containers to store
its data. Table and index containers have fixed size pages. The
Write Ahead Log contains variable size records.</p>
</div>
<div class="section" id="storage-container-registry">
<h2><a class="toc-backref" href="#id42">Storage Container Registry</a></h2>
<p>Container names are usually not good identifiers for the rest of the
system. Integer identifiers are better, especially when other
objects need to refer to specific containers. Integers take less
amount of storage, and also remove the dependency between the
container's name and the rest of the system. To support this
requirement, the <tt class="docutils literal"><span class="pre">org.simpledbm.rss.api.st.StorageManager</span></tt>
interface is provided, which maintains a mapping of
StorageContainers to integer identifiers. Note that the Storage
sub-system does not decide how to map the containers to ids; it
merely enables the registration of these mappings and allows
StorageContainer objects to be retrieved using their numeric
identifiers.</p>
<pre class="literal-block">
StorageContainerFactory storageFactory
   = new FileStorageContainerFactory();
StorageManager storageManager = new StorageManagerImpl();
StorageContainer sc = storageFactory.open(&quot;dual&quot;);
storageManager.register(0, sc);
</pre>
<p>Above sample code registers the container named &quot;dual&quot; to the
storage manager and identifies this with the integer value 0. Other
modules may obtain access to the storage container as follows:</p>
<pre class="literal-block">
StorageContainer sc = storageManager.getInstance(0);
</pre>
</div>
<div class="section" id="storable-interface-and-object-serialization">
<h2><a class="toc-backref" href="#id43">Storable Interface and Object serialization</a></h2>
<p>SimpleDBM requires some way of serializing and de-serializing
objects from a byte stream. Java provides the java.io.Serializable
interface and associated technology for this, however, the default
mechanism is unsuitable for use in SimpleDBM. The problem with the
default method is that the language decides how to map type
information to the stream. Since this has to be done in a generic
manner, it cannot be optimised for space. In contrast, SimpleDBM can
use the 2-byte short integer type code used in the Object Registry
module to efficiently store type information.</p>
<p>SimpleDBM provides the <tt class="docutils literal"><span class="pre">org.simpledbm.rss.api.st.Storable</span></tt>
interface as a substitute for <tt class="docutils literal"><span class="pre">java.io.Serializable</span></tt> interface.
<tt class="docutils literal"><span class="pre">Storable</span></tt> interface requires the object to be able to predict
its stored size in bytes via the <tt class="docutils literal"><span class="pre">getStoredLength()</span></tt> method. It
also requires the object to be able to stream itself to a
<tt class="docutils literal"><span class="pre">ByteBuffer</span></tt> object, and also restore its contents from a
<tt class="docutils literal"><span class="pre">ByteBuffer</span></tt> object.</p>
</div>
</div>
<div class="section" id="latch-manager">
<h1><a class="toc-backref" href="#id44">Latch Manager</a></h1>
<div class="section" id="id3">
<h2><a class="toc-backref" href="#id45">Overview</a></h2>
<p>A Latch is an efficient lock that is used by the system to manage
concurrent access to physical structures. In many ways, Latches are
similar to Mutexes, however, latches supports additional lock modes,
such as Shared locks and Update locks.</p>
</div>
<div class="section" id="latch-modes">
<h2><a class="toc-backref" href="#id46">Latch modes</a></h2>
<p>SimpleDBM implements two types of latches. A ReadWrite Latch
supports two lock modes:</p>
<dl class="docutils">
<dt>Shared mode</dt>
<dd>is compatible with Shared mode but incompatible with Exclusive</dd>
<dt>Exclusive mode</dt>
<dd>incompatible with any other mode.</dd>
</dl>
<p>A ReadWriteUpdate latch is an enhanced version that supports an
additional Update mode lock.</p>
<dl class="docutils">
<dt>Update mode</dt>
<dd>compatible with Shared mode but incompatible with
Update or Exclusive modes. Note that the Shared mode locks are
incompatible with Update mode locks.</dd>
</dl>
<p>An Update lock may be upgraded to Exclusive lock, and conversely, an
Exclusive lock may be downgraded to an Update lock. An Update lock
may also be downgraded to a Shared lock.</p>
</div>
<div class="section" id="implementation-and-performance-notes">
<h2><a class="toc-backref" href="#id47">Implementation and Performance Notes</a></h2>
<p>The SimpleDBM Latch interface is designed to be compatible with the
Java 5.0 ReentrantReadWriteLock interface. This allows the ReadWrite
Latch implementation to be based upon the Java primitive.</p>
<p>The ReadWrite Latch is likely to be more efficient than the
ReadWriteUpdate Latch.</p>
</div>
<div class="section" id="obtaining-a-latch-instance">
<h2><a class="toc-backref" href="#id48">Obtaining a latch instance</a></h2>
<p>SimpleDBM implements a factory class for creating Latch objects. The
factory supports instantiating a ReadWrite latch, or a
ReadWriteUpdate latch. There is also a default mode which results in
ReadWrite latch.</p>
</div>
</div>
<div class="section" id="log-manager">
<h1><a class="toc-backref" href="#id49">Log Manager</a></h1>
<div class="section" id="id4">
<h2><a class="toc-backref" href="#id50">Overview</a></h2>
<p>The Write Ahead Log plays a crucial role in a DBMS. It provides the
basis for recoverability. It is also a critical part of the system
that has a massive impact on performance of an OLTP system.</p>
<p>Conceptually, the Log can be thought of as an ever growing
sequential file. In the form of Log Records, the Log contains a
history of all changes made to the database. Each Log Record is
uniquely identified by a number called the Log Sequence Number
(LSN). The LSN is designed in such a way that given an LSN, the
system can locate the corresponding Log Record quickly. LSNs are
assigned in strict ascending order (monotonicity). This is an
important property when it comes to recovery.</p>
<p>During the progress of a Transaction, the a DBMS records in the Log
all the changes made by the transaction. The Log records can be used
to recover the system if there is a failure, or they can be used to
undo the changes made by a transaction.</p>
<p>Initially, Log Records are stored in memory. They are flushed to
disk during transaction commits, and also during checkpoints. In the
event of a crash, it is possible to lose the log records that were
not flushed to disk. This does not cause a problem, however, because
by definition these log records must correspond to changes made by
incomplete transactions. Also, the WAL protocol (described below)
ensures that such Log records do not contain changes that have
already been persisted within the database.</p>
</div>
<div class="section" id="write-ahead-log-wal-protocol">
<h2><a class="toc-backref" href="#id51">Write Ahead Log (WAL) Protocol</a></h2>
<p>The WAL protocol requires the following conditions to hold true:</p>
<ol class="arabic simple">
<li>All changes made by a transaction must be recorded in the Log
and the Log must be flushed to disk before the transaction is
committed.</li>
<li>A database buffer page may not be modified until its modifications
have been logged. A buffer page may not be saved to disk until
all its associated log records have been saved to disk.</li>
<li>While the buffer page is being modified and the Log is being
updated, an Exclusive latch (a type of fast lock) must be held
on the page to ensure that order in which changes are recorded
in the Log correspond to the order in which they were made.</li>
</ol>
<p>Consequences of above rules are:</p>
<ul class="simple">
<li>If a Log Record was not saved to disk, it can be safely ignored,
because any changes contained in it are guaranteed to belong to
uncommitted transactions. Also, such Log Records cannot represent
changes that have been made persistent in the database.</li>
<li>Log records represent changes to the system in the correct order.
The latching protocol ensures that if two Log records represent
changes to the same Page, then the ordering of these records
reflects the order in which the changes were made to the page.</li>
</ul>
</div>
<div class="section" id="advantages-of-wal">
<h2><a class="toc-backref" href="#id52">Advantages of WAL</a></h2>
<p>Typically, in an OLTP system, updates tend to be random and can
affect different parts of the disk at a point in time. In
comparison, writes to the Log are always sequential. If it were
necessary to flush all changes made by the DBMS to disk at commit
time, it would have a massive impact on performance because of the
randomness of the disk writes. However, in a WAL system, only the
Log needs to be flushed to disk at Commit. Thus, the Log has the
effect of transforming random writes into serial writes, thereby
improving performance significantly.</p>
</div>
<div class="section" id="usage-notes">
<h2><a class="toc-backref" href="#id53">Usage Notes</a></h2>
<p>The Log Manager interface does not make any assumptions about log
records. In fact, it does not specify the format of a log record.</p>
</div>
<div class="section" id="simpledbm-implementation-of-the-log">
<h2><a class="toc-backref" href="#id54">SimpleDBM Implementation of the Log</a></h2>
<p>The SimpleDBM Log maintains control information separately from log
files. For safety, multiple copies of control information are stored
(though at present, only the first control file is used when opening
the Log).</p>
<p>Logically, the Log is organized as a never ending sequence of log
records. Physically, the Log is split up into log files. There is a
fixed set of online log files, and a dynamic set of archived log
files. The set of online log files is called a Log Group.</p>
<p>Each Log Group consists of a set of pre-allocated log files of the
same size. The maximum number of groups possible is 3, and the
maximum number of log files within a group is 8. Note that each
group is a complete set in itself - the Log is recoverable if any
one of the groups is available, and if the archived log files are
available. If more than one group is created, it is expected that
each group will reside on a different disk sub-system.</p>
<p>The Log Groups are allocated when the Log is initially created. The
log files within a group are also pre-allocated. However, the
content of the online log files changes over time.</p>
<p>Logically, in the same way that the Log can be viewed as a sequence
of Log Records, it can also be thought of as a sequence of Log
Files. The Log Files are numbered in sequence, starting from 1. The
Log File sequence number is called LogIndex. At any point in time,
the physical set of online log files will contain a set of logical
log files. For example, if there are 3 physical files in a Log
Group, then at startup, the set of logical log files would be 1, 2
and 3. After some time, the log file 1 would get archived, and in
its place a new logical log file 4 would be created. The set now
would now consist of logical log files 2, 3 and 4.</p>
<p>When a log record is written to disk, it is written out to an online
log file. If there is more than one group, then the log record is
written to each of the groups. The writes happen in sequence to
ensure that if there is a write failure, damage is restricted to one
Log Group. Note that due to the way this works, having more than 1
group will slow down log writes. It is preferable to use hardware
based disk mirroring of log files as opposed to using multiple log
groups.</p>
<p>When new log records are created, they are initially stored in the
log buffers. Log records are written out to log files either because
of a client request to flush the log, or because of the periodic
flush event.</p>
<p>During a flush, the system determines which log file to use. There
is the notion of Current log file, which is where writes are
expected to occur. If the current log file is full, it is put into a
queue for archiving, and the log file is switched. Until an online
log file has been archived, its physical file cannot be reused. A
separate archive thread monitors archive requests and archives log
files in the background.</p>
<p>Only one flush is permitted to execute at any point in time.
Similarly, only one archive is permitted to execute at any point in
time. However, multiple clients are allowed to concurrently insert
and read log records, even while flushing and archiving is going on,
except under following circumstances.</p>
<ol class="arabic simple">
<li>Log inserts cannot proceed if the system has used up more
memory than it should. In that case, it must wait for some memory to
be freed up. To ensure maximum concurrency, the memory calculation
is approximate.</li>
<li>A Log flush cannot proceed if all the online log files are full.
In this situation, the flush must wait for at least one file to be
archived.</li>
<li>When reading a log record, if the online log file containing the
record is being archived, the reader may have to wait for the status
of the log file to change, before proceeding with the read.
Conversely, if a read is active, the archive thread must wait for
the read to be over before changing the status of the log file.</li>
</ol>
<p>If archive mode is ON, log files are archived before being re-used.
Otherwise, they can be reused if the file is no longer needed -
however this is currently not implemented. By default archive mode
is ON.</p>
</div>
<div class="section" id="limitations-of-current-design">
<h2><a class="toc-backref" href="#id55">Limitations of current design</a></h2>
<p>A Log record cannot span log files, and it must fit within a single
log buffer. Thus the size of a log record is limited by the size of
a log buffer and by the size of a log file. As a workaround to this
limitation, clients can split the data into multiple log records,
but in that case, clients are responsible for merging the data back
when reading from the Log.</p>
</div>
<div class="section" id="operations">
<h2><a class="toc-backref" href="#id56">Operations</a></h2>
<div class="section" id="creating-a-new-log-instance">
<h3><a class="toc-backref" href="#id57">Creating a new Log Instance</a></h3>
<p>Several parameters must be supplied when creating a new log
instance. These are specified using a Java Properties object.</p>
<table border="1" class="docutils">
<colgroup>
<col width="37%" />
<col width="63%" />
</colgroup>
<tbody valign="top">
<tr><td>Property Name</td>
<td>Description</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">log.ctl.{n}</span></tt></td>
<td>The fully qualified path to the
log control file. The first file should be specified as
<tt class="docutils literal"><span class="pre">log.ctl.1</span></tt>, second as <tt class="docutils literal"><span class="pre">log.ctl.2</span></tt>, and so on. Up to a
maximum of 3 can be specified. Default is 2.</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">log.groups.{n}.path</span></tt></td>
<td>The path where log files of a group should be stored.
The first log group is specified as <tt class="docutils literal"><span class="pre">log.groups.1.path</span></tt>,
the second as <tt class="docutils literal"><span class="pre">log.groups.2.path</span></tt>,
and so on. Up to a maximum of 3 log groups can be
specified. Default number of groups is 1. Path defaults
to current directory.</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">log.archive.path</span></tt></td>
<td>Defines the path for storing archive files. Defaults to
current directory.</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">log.group.files</span></tt></td>
<td>Specifies the number of log files within each group.
Up to a maximum of 8 are allowed. Defaults to 2.</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">log.file.size</span></tt></td>
<td>Specifies the size of each log file in
bytes. Default is 2 KB.</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">log.buffer.size</span></tt></td>
<td>Specifies the size of the log buffer
in bytes. Default is 2 KB.</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">log.buffer.limit</span></tt></td>
<td>Sets a limit on the maximum number of
log buffers that can be allocated. Default is 10 *
log.group.files.</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">log.flush.interval</span></tt></td>
<td>Sets the interval (in seconds)
between log flushes. Default is 6 seconds.</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">log.explicitFlushRequests</span></tt></td>
<td>Boolean value, if set, disables
log flushes requested explicitly by the Buffer Manager
or Transaction Manager. Log flushes still occur during
checkpoints and log switches. By reducing the log flushes,
performance is improved, but transactions may not be
durable. Only those transactions will survive a system
crash that have all their log records on disk.</td>
</tr>
</tbody>
</table>
<p>Here is an example:</p>
<pre class="literal-block">
LogFactory factory = new LogFactoryImpl();
Properties properties = new Properties();
properties.setProperty(&quot;log.ctl.1&quot;, &quot;ctl.a&quot;);
properties.setProperty(&quot;log.ctl.2&quot;, &quot;ctl.b&quot;);
properties.setProperty(&quot;log.groups.1.path&quot;, &quot;.&quot;);
properties.setProperty(&quot;log.archive.path&quot;, &quot;.&quot;);
properties.setProperty(&quot;log.group.files&quot;, &quot;3&quot;);
properties.setProperty(&quot;log.file.size&quot;, &quot;16384&quot;);
properties.setProperty(&quot;log.buffer.size&quot;, &quot;16384&quot;);
properties.setProperty(&quot;log.buffer.limit&quot;, &quot;4&quot;);
properties.setProperty(&quot;log.flush.interval&quot;, &quot;30&quot;);
factory.createLog(properties);
</pre>
</div>
<div class="section" id="opening-a-log-instance">
<h3><a class="toc-backref" href="#id58">Opening a log instance</a></h3>
<p>Once a Log has been created, it can be opened for use. Opening the
log also starts back ground threads that handle periodic log flushes
and archival of log files. When the log is closed, the background
threads are shut down.</p>
<p>Following sample code shows how this is done:</p>
<pre class="literal-block">
LogFactory factory = new LogFactoryImpl();
Properties properties = new Properties();
properties.setProperty(&quot;log.ctl.1&quot;, &quot;ctl.a&quot;);
properties.setProperty(&quot;log.ctl.2&quot;, &quot;ctl.b&quot;);
properties.setProperty(&quot;log.groups.1.path&quot;, &quot;.&quot;);
properties.setProperty(&quot;log.archive.path&quot;, &quot;.&quot;);
properties.setProperty(&quot;log.group.files&quot;, &quot;3&quot;);
properties.setProperty(&quot;log.file.size&quot;, &quot;16384&quot;);
properties.setProperty(&quot;log.buffer.size&quot;, &quot;16384&quot;);
properties.setProperty(&quot;log.buffer.limit&quot;, &quot;4&quot;);
properties.setProperty(&quot;log.flush.interval&quot;, &quot;30&quot;);
LogMgr log = factory.openLog(properties);
try {
    // do some work
} finally {
    if (log != null)
        log.close();
}
</pre>
<p>Note the use of finally block to ensure that the log is properly
closed.</p>
</div>
<div class="section" id="inserting-new-log-records">
<h3><a class="toc-backref" href="#id59">Inserting new log records</a></h3>
<p>The Log Manager does not care about the contents of the log record.
It treats the contents as a byte stream. This is illustrated in the
following example:</p>
<pre class="literal-block">
LogMgr log = factory.openLog(null);
try {
    String s = &quot;hello world!&quot;;
    byte[] b = s.getBytes();
    Lsn lsn = log.insert(b, b.length);
} finally {
    if (log != null)
        log.close();
}
</pre>
<p>Each new log record is assigned a unique sequence number known as
the Log Sequence Number (LSN). This can be used later on to retrieve
the log record.</p>
</div>
<div class="section" id="flushing-the-log">
<h3><a class="toc-backref" href="#id60">Flushing the Log</a></h3>
<p>When new log records are created, initially they are stored in the
Log Buffers. The log records are flushed to disk either upon request
or by the background thread that periodically flushes the Log.
Clients can request the log to be flushed upto a specified LSN. Note
that this is a blocking call, i.e., the client will be blocked until
the flush is completed.</p>
<p>Example:</p>
<pre class="literal-block">
String s = &quot;hello world!&quot;;
byte[] b = s.getBytes();
Lsn lsn = log.insert(b, b.length);
log.flush(lsn);
</pre>
<p>Typically, flush requests are issued by Transaction Manager, when a
transaction commits or aborts, or by the Buffer Manager when it is
about to write a dirty buffer.</p>
</div>
<div class="section" id="reading-log-records">
<h3><a class="toc-backref" href="#id61">Reading Log records</a></h3>
<p>Log records can be read individually or using a scan. The Log
Manager allows both forward and backward scans of the Log. A
starting LSN can be specified; if this is not specified then the
scanning will begin from the first or last record, depending upon
whether it is a forward or backward scan.</p>
<p>Shown below is an example of directly accessing a log record by its
LSN:</p>
<pre class="literal-block">
Lsn myLsn = ...;
LogRecord logrec = log.read(myLsn);
byte[] data = logrec.getData();
</pre>
<p>Shown below is an example of using the Log Scan facility:</p>
<pre class="literal-block">
void readAllRecords(LogMgr log) throws Exception {
    LogReader reader = log.getForwardScanningReader(null);
    try {
        for (;;) {
            LogRecord rec = reader.getNext();
            if (rec == null) {
                break;
            }
            printRecord(rec);
        }
    }
    finally {
        if (reader != null)
            reader.close();
    }
}
</pre>
</div>
<div class="section" id="checkpoint-records">
<h3><a class="toc-backref" href="#id62">Checkpoint Records</a></h3>
<p>In transactional systems there is often a need to maintain special
checkpoint records that contain a snapshot of the system at a point
in time. Checkpoint records can be handled in the same way as normal
log records, however, the Log Manager also maintains information
about the most recent checkpoint record. Whenever a checkpoint
record is written, the Log Manager should be informed about its LSN.
This ensures that at the next flush, the Log Control files are
updated.</p>
<pre class="literal-block">
CheckpointRecord checkpointRec = new CheckpointRecord();
Lsn checkpointLsn = log.insert(checkpointRec.getData(),
        checkpointRec.getLength());
logmgr.setCheckpointLsn(checkpointLsn);
logmgr.flush(checkpointLsn);
</pre>
<p>The LSN of the last checkpoint record can be retrieved at any time
using the getCheckpointLsn() method. Note that if the Checkpoint
Record is too large and needs to be broken up into smaller records,
then the checkpointLsn should be set to the first checkpoint record.</p>
</div>
</div>
</div>
<div class="section" id="lock-manager">
<h1><a class="toc-backref" href="#id63">Lock Manager</a></h1>
<div class="section" id="id5">
<h2><a class="toc-backref" href="#id64">Introduction</a></h2>
<p>All multi-user transactional systems use some form of locking to
ensure that concurrent transactions do not conflict with each other.
Depending upon the level of consistency guaranteed by the
transactional system the number and type of locks used can vary.</p>
<p>In a single user system, no locking is needed. Transaction are
automatically consistent, as only one transaction can execute at any
point in time.</p>
</div>
<div class="section" id="locking-basics">
<h2><a class="toc-backref" href="#id65">Locking Basics</a></h2>
<p>In multi-user systems, transactions must be allowed to proceed
concurrently if reasonable performance is to be obtained. However,
this means that unless some form of locking is used, data
consistency problems will arise. For example, if two transactions
update the same record at the same time, one of the updates may be
lost.</p>
<p>To prevent this sort of thing from happening, each transaction must
lock the data that it updates or reads. A lock is a mechanism by
which access to the record is restricted to the transaction that
owns the lock. Furthermore, a lock restricts the type of operation
that is permitted to occur. For example, a Shared lock can be owned
by multiple transactions concurrently and allows read operations. An
Exclusive lock permits both read and write operations but can only
be granted to one transaction at any point on time. Moreover Shared
locks and Exclusive locks are incompatible; this means that if a
Shared Lock is held by a transaction on a record, another
transaction cannot obtain an Exclusive lock on the same record, and
vice-versa.</p>
</div>
<div class="section" id="two-phase-locking-and-repeatable-read-isolation-level">
<h2><a class="toc-backref" href="#id66">Two-Phase Locking and Repeatable Read Isolation Level</a></h2>
<p>Not only must a record be locked when it is updated, the transaction
must hold the lock until the transaction is committed or aborted.
This strategy leads to the basic rule of two-phase locking, which
requires that a transaction must manage its locks in two distinct
phases. In the first phase, the transaction is permitted to acquire
locks, but cannot release any locks. The first phase lasts right up
to the moment the transaction is completed, i.e., either committed
or aborted. In the second phase, when the transaction is committed
or aborted, all locks are released. No further locks can be acquired
in this phase. Strict two phase locking ensures that despite
concurrent running of transactions, each transaction has the
appearance of running in isolation. Strict two-phase locking
strategy provides a level of consistency called Repeatable Read.</p>
</div>
<div class="section" id="read-committed-isolation-level">
<h2><a class="toc-backref" href="#id67">Read Committed Isolation Level</a></h2>
<p>This basic strategy can be modified to obtain greater concurrency at
the cost of data consistency. For example, read locks can be
released early to allow other transactions to read data. While this
increases concurrency, it does mean that reads are not repeatable,
because the original transaction may find that the data it read
previously has been modified by the time it is read a second time.
This level of consistency is known as Read Committed.</p>
</div>
<div class="section" id="serializable-isolation-level">
<h2><a class="toc-backref" href="#id68">Serializable Isolation Level</a></h2>
<p>Although the Repeatable Read level of consistency prevents data that
has been read by one transaction from being modified by another, it
does not prevent the problem of phantom reads, which occurs when new
records are inserted. For example, if a range of records is read
twice by the same transaction, and another transaction has inserted
new records in the time interval between the two reads, then the
second read will encounter records that did not appear the first
time. To prevent this type of phantom reads from occurring, locking
has to be made even more comprehensive. Rather than locking one
record, certain operations need to lock entire ranges of records,
even non-existent ones. This is typically achieved using a logical
convention; a lock on a particular data item represents not only a
lock on that data, but also the range of data up to and including
the data item being locked. For example, if there are two records A
and C, then a lock on C would encompass the entire range of data
between A and C, excluding A, but including and up to C.</p>
</div>
<div class="section" id="design-choices">
<h2><a class="toc-backref" href="#id69">Design choices</a></h2>
<p>The Locking subsystem specified in SimpleDBM requires that locks
should be implemented independently of the objects being locked. In
order for locking to work, all participants must agree to agree to
use the locking system and abide by the rules.</p>
<p>Another design constraint is that the interface is geared towards a
memory based implementation. This places a constraint on the number
of locks that can be held within the system, because a large number
of locks would require a prohibitively large amount of memory.</p>
<p>Some database systems, Oracle, in particular, use markers within the
databases disk pages to represent locks. A lock byte is used, for
instance, to denote whether a row is locked or not. The advantage of
Oracle's approach is that there are no constraints on the number of
locks the system can handle. The disadvantage is that the lock
status is maintained in persistent storage, therefore changing the
lock status can make a page dirty. Oracle overcomes this issue in
two ways. Firstly, it uses a multi-version system that does not
required read locks. Thus, locks are used only for updates, and
since updates cause database pages to be touched anyway, using a
lock status byte does not pose a problem. Secondly, Oracle avoids
updating the lock status byte when locks are released, by using
information about the transaction status to infer that a lock has
been released.</p>
<p>The interface for the Locking System specified in this package does
not support implementations of the type used in Oracle.</p>
<p>In some systems, locking is based upon facilities provided by the
underlying operating system. For instance, most operating systems
support some form of file locking. Since database records are laid
out into regions within a file system, file system locks can be
applied on records. No major database system does this, however.
This is because locking a region in the file would prevent all
access to that region, which would cause other problems. Even when
systems do use file system locks, typically, some form of logical
locking is used. For example, in DBASE III based systems, a single
byte in the file represents a record lock. In general, relying upon
file system locks can be source of numerous problems, such as
portability of the system, performance, etc.</p>
</div>
<div class="section" id="lock-modes">
<h2><a class="toc-backref" href="#id70">Lock Modes</a></h2>
<p>The SimpleDBM Lock Manager supports the following Lock Modes:</p>
<dl class="docutils">
<dt>INTENTION_SHARED</dt>
<dd>Indicates the intention to read data at a lower level of
granularity.</dd>
<dt>INTENTION_EXCLUSIVE</dt>
<dd>Indicates the intention to update data at a lower level of
granularity.</dd>
<dt>SHARED</dt>
<dd>Permits readers.</dd>
<dt>SHARED_INTENTION_EXCLUSIVE</dt>
<dd>Indicates SHARED lock at current level and intention to update
data at a lower level of granularity.</dd>
<dt>UPDATE</dt>
<dd>Indicates intention to update, Permits readers.</dd>
<dt>EXCLUSIVE</dt>
<dd>Prevents access by other users.</dd>
</dl>
<div class="section" id="lock-compatibility-matrix">
<h3><a class="toc-backref" href="#id71">Lock Compatibility Matrix</a></h3>
<p>The lock compatibility matrix for above is given below:</p>
<table border="1" class="docutils">
<caption>Lock Compatibility Table</caption>
<colgroup>
<col width="20%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
</colgroup>
<tbody valign="top">
<tr><td>Mode</td>
<td>NONE</td>
<td>IS</td>
<td>IX</td>
<td>S</td>
<td>SIX</td>
<td>U</td>
<td>X</td>
</tr>
<tr><td>NONE</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
</tr>
<tr><td>Intent
Shared</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
<td>N</td>
<td>N</td>
</tr>
<tr><td>Intent
Exclusive</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
<td>N</td>
<td>N</td>
<td>N</td>
<td>N</td>
</tr>
<tr><td>Shared</td>
<td>Y</td>
<td>Y</td>
<td>N</td>
<td>Y</td>
<td>N</td>
<td>N</td>
<td>N</td>
</tr>
<tr><td>Shared
Intent
Excluive</td>
<td>Y</td>
<td>Y</td>
<td>N</td>
<td>N</td>
<td>N</td>
<td>N</td>
<td>N</td>
</tr>
<tr><td>Update</td>
<td>Y</td>
<td>N</td>
<td>N</td>
<td>Y</td>
<td>N</td>
<td>N</td>
<td>N</td>
</tr>
<tr><td>Exclusive</td>
<td>Y</td>
<td>N</td>
<td>N</td>
<td>N</td>
<td>N</td>
<td>N</td>
<td>N</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="lock-conversions">
<h3><a class="toc-backref" href="#id72">Lock Conversions</a></h3>
<p>SimpleDBM's Lock Manager also supports Lock Conversions. The
following table shows how lock conversions are handled:</p>
<table border="1" class="docutils">
<caption>Lock Conversion Table</caption>
<colgroup>
<col width="20%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
</colgroup>
<tbody valign="top">
<tr><td>Mode</td>
<td>NONE</td>
<td>IS</td>
<td>IX</td>
<td>S</td>
<td>SIX</td>
<td>U</td>
<td>X</td>
</tr>
<tr><td>NONE</td>
<td>NONE</td>
<td>IS</td>
<td>IX</td>
<td>S</td>
<td>SIX</td>
<td>U</td>
<td>X</td>
</tr>
<tr><td>Intent
Shared</td>
<td>IS</td>
<td>IS</td>
<td>IX</td>
<td>S</td>
<td>SIX</td>
<td>U</td>
<td>X</td>
</tr>
<tr><td>Intent
Exclusive</td>
<td>IX</td>
<td>IX</td>
<td>IX</td>
<td>SIX</td>
<td>SIX</td>
<td>X</td>
<td>X</td>
</tr>
<tr><td>Shared</td>
<td>S</td>
<td>S</td>
<td>SIX</td>
<td>S</td>
<td>SIX</td>
<td>U</td>
<td>X</td>
</tr>
<tr><td>Shared
Intent
Exclusive</td>
<td>SIX</td>
<td>SIX</td>
<td>SIX</td>
<td>SIX</td>
<td>SIX</td>
<td>SIX</td>
<td>X</td>
</tr>
<tr><td>Update</td>
<td>U</td>
<td>U</td>
<td>X</td>
<td>U</td>
<td>SIX</td>
<td>U</td>
<td>X</td>
</tr>
<tr><td>Exclusive</td>
<td>X</td>
<td>X</td>
<td>X</td>
<td>X</td>
<td>X</td>
<td>X</td>
<td>X</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="id6">
<h2><a class="toc-backref" href="#id73">Operations</a></h2>
<div class="section" id="obtaining-an-instance-of-lock-manager">
<h3><a class="toc-backref" href="#id74">Obtaining an instance of Lock Manager</a></h3>
<p>SimpleDBM provides a factory class for generating instances of the
Lock Manager. Note that locks are meaningful only within an instance
of the Lock Manager -- if there are two Lock Manager instances, each
will have its own set of locks.</p>
<p>Following sample code shows how to obtain an instance of the Lock
Manager.</p>
<pre class="literal-block">
LockMgrFactory factory = new LockMgrFactoryImpl();
Properties props = new Properties();
LockMgr lockmgr = factory.create(props);
</pre>
<p>The only property that can be set is the Hash Table size.</p>
</div>
<div class="section" id="lockable-objects">
<h3><a class="toc-backref" href="#id75">Lockable objects</a></h3>
<p>Any object can be locked. The only requirement is that the object
should implement the <tt class="docutils literal"><span class="pre">hashCode()</span></tt> and <tt class="docutils literal"><span class="pre">equals()</span></tt> methods.
For the system to work correctly, lockable objects should be
immutable -- once created they must not be modified. Clearly, if the
object is modified while it is referenced in the lock tables, then
the system will malfunction, as the object will no longer respond to
<tt class="docutils literal"><span class="pre">hashCode()</span></tt> and <tt class="docutils literal"><span class="pre">equals()</span></tt> in a consistent manner.</p>
</div>
<div class="section" id="lock-owners">
<h3><a class="toc-backref" href="#id76">Lock Owners</a></h3>
<p>Every lock must have an owner. The LockMgr interface allows any
object to be lock owner; the only requirement is that the object
must implement the <tt class="docutils literal"><span class="pre">equals()</span></tt> method.</p>
</div>
<div class="section" id="lock-durations">
<h3><a class="toc-backref" href="#id77">Lock Durations</a></h3>
<p>Locks can be acquired for an <tt class="docutils literal"><span class="pre">INSTANT_DURATION</span></tt> or
<tt class="docutils literal"><span class="pre">MANUAL_DURATION</span></tt>. Instant duration locks are not acquired in
reality -- the caller is delayed until the lock becomes available.
Manual duration locks are held until they are released. Such locks
have a reference count attached to them. If the lock is acquired
more than once, the reference count is incremented. The lock will
not be released until the reference count becomes zero.</p>
<p>Typically, a Transaction will hold locks until the transaction ends.
In some cases, SHARED locks may be released early, for example, in
the READ COMMITTED Isolation Level.</p>
</div>
<div class="section" id="acquiring-and-releasing-locks">
<h3><a class="toc-backref" href="#id78">Acquiring and releasing locks</a></h3>
<p>Locks can be acquired using the <tt class="docutils literal"><span class="pre">acquire()</span></tt> method provided by
the LockMgr interface. The acquire method returns a Handle to the
lock, which can be used subsequently to release the lock. Example:</p>
<pre class="literal-block">
LockMgr lockmgr = new LockMgrImpl(71);
Object owner = new Integer(1);
Object lockname = new Integer(10);
LockHandle handle = lockmgr.acquire(owner, lockname,
    LockMode.EXCLUSIVE, LockDuration.MANUAL_DURATION, -1);
// do some work
handle.release(false);
</pre>
</div>
<div class="section" id="limitations-in-current-implementation">
<h3><a class="toc-backref" href="#id79">Limitations in current implementation</a></h3>
<p>The biggest limitation is the lack of a Deadlock Detector. SimpleDBM
uses lock timeout as a workaround to this problem.</p>
</div>
</div>
</div>
<div class="section" id="page-manager">
<h1><a class="toc-backref" href="#id80">Page Manager</a></h1>
<div class="section" id="overview-of-page-manager-module">
<h2><a class="toc-backref" href="#id81">Overview of Page Manager module</a></h2>
<p>The storage unit of a database system is a contiguous set of bytes
known as a Page. In SimpleDBM, pages are contained with logical
units called Storage Containers. The default implementation maps
containers to Operating System files.</p>
<p>A page is typically a fixed size block within the storage container.
The Page Manager module encapsulates the knowledge about how pages
map to containers. It knows about page sizes, and also knows how to
read/write pages from storage containers. By isolating this
knowledge into a separate module, the rest of the system is
protected. For example, the Buffer Manager module can work with
different paging strategies by switching the Page Manager module.</p>
<p>Note that the Page Manager module does not worry about the contents
of the page, except for the very basic and common stuff that must be
part of every page, such as page Id, page LSN, and page type. It is
expected that other modules will extend the basic page type and
implement additional features. The Page Manager does provide the
base class for all Page implementations. It also provides a generic
factory class that can instantiate pages of different types.</p>
</div>
<div class="section" id="interactions-with-other-modules">
<h2><a class="toc-backref" href="#id82">Interactions with other modules</a></h2>
<p>The Buffer Manager module uses the Page Manager module to read/write
pages from storage containers and also to create new instances of
pages.</p>
<p>The Page Manager module requires the services of the Object Registry
module in order to create instances of pages from type codes.</p>
<p>Page Manager module also interacts with the Storage Manager module
for access to Storage Containers.</p>
<p>Each page is allocated a Latch to manage concurrent access to it.
The Page Manager therefore requires the services of the Latch
Manager.</p>
</div>
<div class="section" id="page-class">
<h2><a class="toc-backref" href="#id83">Page class</a></h2>
<p>The page manager implements an abstract Page class that is the root
of the Page hierarchy. All other page types derive from this class.
The simplest of Page classes that one could create is shown below:</p>
<pre class="literal-block">
public class RawPage extends Page {
  public RawPage() {
      super();
  }
  &#64;Override
  public void init() {
      // does nothing
  }
}
</pre>
<div class="section" id="page-size-and-implementation-of-storable-interface">
<h3><a class="toc-backref" href="#id84">Page Size and implementation of Storable interface</a></h3>
<p>The Page class implements the Storable interface. However, unlike
other implementations, a Page has a fixed length which is defined by
the Page Factory responsible for creating it. The Page obtains the
page size from the Page Factory instance and uses that to determine
its persistent size. Sub-classes cannot change this value. This
means that the page size of all pages managed by a particular Page
Factory instance is always the same.</p>
<p>Sub-classes of course still need to implement their own store() and
retrieve() methods. These methods should always invoke their super
class counterparts before processing local content.</p>
<p>Example:</p>
<pre class="literal-block">
public class RawPage extends Page {
  int i;
  public RawPage() {
    super();
  }
  &#64;Override
  public void init() {
    i = 0;
  }
  &#64;Override
  public void store(ByteBuffer bb) {
    super.store(bb);
    bb.putInt(i);
  }
  &#64;Override
  public void retrieve(ByteBuffer bb) {
    super.retrieve(bb);
    i = bb.getInt();
  }
}
</pre>
</div>
<div class="section" id="how-various-page-types-are-managed">
<h3><a class="toc-backref" href="#id85">How various Page types are managed</a></h3>
<p>SimpleDBM modules do not know in advance what page types are to be
used. Some of the modules define their own page types. However,
despite this the Buffer Manager, and the Transaction Manager modules
must handle pages, even read and write them to the disk as
necessary. This is made possible as follows:</p>
<ul class="simple">
<li>Each Page type is given a typecode in the Object Registry.
This allows the Page Factory to obtain instances of specific
Page types given the typecode.</li>
<li>The typecode is stored in the first two bytes (as a short
integer) of the Page when the page is persisted. When reading
a page, the first two bytes are inspected to determine the
correct Page type to instantiate. Reading and writing various
page types is managed by the Page Factory implementation.</li>
<li>The Buffer Manager uses the Page Factory implementation to
generate new instances of Pages or to read/write specific
pages.</li>
<li>The abstract Page class provides a common interface for
all Pages. This interface implements all the functionality
that is required by the Transaction Manager module to manage
updates to pages.</li>
</ul>
</div>
<div class="section" id="page-factory">
<h3><a class="toc-backref" href="#id86">Page Factory</a></h3>
<p>Creating a page factory is relatively simple:</p>
<pre class="literal-block">
StorageContainerFactory storageFactory =
    new FileStorageContainerFactory();
ObjectFactory objectFactory = new ObjectFactoryImpl();
StorageManager storageManager = new StorageManagerImpl();
LatchFactory latchFactory = new LatchFactoryImpl();
PageFactory pageFactory = new PageFactoryImpl(objectFactory,
    storageManager, latchFactory);
</pre>
<p>Note that the Page Factory requires access to the Object Registry,
the Latch Manager and the Storage Manager.</p>
</div>
<div class="section" id="storing-and-retrieving-pages">
<h3><a class="toc-backref" href="#id87">Storing and retrieving Pages</a></h3>
<p>Before pages can be stored or retrieved, the appropriate Storage
Containers must be created/opened and registered with the Storage
Manager. Also, the Page types must be registered with the Object
Registry. Following sample code shows how this may be done:</p>
<pre class="literal-block">
String name = &quot;testfile.dat&quot;;
// Create a new storage container called testfile.dat
StorageContainer sc = storageFactory.create(name);
// Assign it a container ID of 1
storageManager.register(1, sc);
// Register the Page Type
objectFactory.register(&quot;mypage&quot;, TYPE_MYPAGE, MyPage.class.getName());
// Create a new instance of the page
MyPage page = (MyPage) pageFactory.getInstance(&quot;mypage&quot;, new PageId(1,
    0));
// Store the page in the container
pageFactory.store(page);
// Retrieve the page from the container
page = (MyPage) pageFactory.retrieve(new PageId(1, 0));
</pre>
</div>
</div>
</div>
<div class="section" id="buffer-manager">
<h1><a class="toc-backref" href="#id88">Buffer Manager</a></h1>
<div class="section" id="id7">
<h2><a class="toc-backref" href="#id89">Overview</a></h2>
<p>The Buffer Manager is a critical component of any DBMS. Its primary
job is to cache disk pages in memory. Typically, a Buffer Manager
has a fixed size Buffer Pool, implemented as an array of in-memory
disk pages. The contents of the Buffer Pool change over time, as
pages are read in, and written out. One of the principle tasks of
the Buffer Manager is to decide which page should stay in memory,
and which should not. The aim is to try to keep the most frequently
required pages in memory. The efficiency of the Buffer Manager can
be measured by its cache hit-rate, which is the ratio of pages found
in the cache, to pages accessed by the system.</p>
<p>In order to decide which pages to maintain in memory, the Buffer
Manager typically implements some form of Least Recently Used (LRU)
algorithm. In the simplest form, this is simply a linked list of all
cached pages, the head of the list representing the least recently
used page, and the tail the most recently used. This is based on the
assumption that if a page was accessed recently, then it is likely
to be accessed again soon. Since every time a page is accessed, it
is moved to the MRU end of the list, therefore over time, the most
frequently accessed pages tend to accumulate on the MRU side. Of
course, if a client reads a large number of temporary pages, then
this scheme can be upset. To avoid this, the Buffer Manager may
support hints, so that a client can provide more information to the
Buffer Manager, which can then use this information to improve the
page replacement algorithm. An example of such a hint would be to
flag temporary pages. The Buffer Manager can then use this knowledge
to decide that instead of the page going to MRU end, it goes to the
LRU end.</p>
</div>
<div class="section" id="id8">
<h2><a class="toc-backref" href="#id90">Interactions with other modules</a></h2>
<p>The Buffer Manager interacts with the Log Manager and the Page
Manager modules. It needs the help of the PageFactory in order to
instantiate new pages, read pages from disk, and write out dirty
pages to disk. In order to support the Write Ahead Log protocol, the
Buffer Manager must ensure that all logs related to the page in
question are flushed prior to the page being persisted to disk.</p>
<p>The Transaction Manager also interacts with the Buffer Manager.
During checkpoints, the Transaction Manager asks for a list of dirty
pages. It uses information maintained by the Buffer Manager to
determine where recovery should start. After a system restart the
Transaction Manager informs the Buffer Manager about the recovery
status of disk pages.</p>
</div>
<div class="section" id="id9">
<h2><a class="toc-backref" href="#id91">Operations</a></h2>
<div class="section" id="creating-a-buffer-manager-instance">
<h3><a class="toc-backref" href="#id92">Creating a Buffer Manager instance</a></h3>
<p>A Buffer Manager instance has a dependency on Log Manager and Page
Factory. These in turn depend upon a few other modules. The
following sample code illustrates the steps required to create a
Buffer Manager instance.</p>
<pre class="literal-block">
LogFactory factory = new LogFactoryImpl();
Properties properties = new Properties();
properties.setProperty(&quot;log.ctl.1&quot;, &quot;ctl.a&quot;);
properties.setProperty(&quot;log.ctl.2&quot;, &quot;ctl.b&quot;);

// Create Storage Factory instance
StorageContainerFactory storageFactory =
    new FileStorageContainerFactory();
// Open Log
LogMgr log = factory.openLog(storageFactory, properties);
// Create Object Registry
ObjectFactory objectFactory = new ObjectFactoryImpl();
// Create Storage Manager instance
StorageManager storageManager = new StorageManagerImpl();
// Create Latch Factory
LatchFactory latchFactory = new LatchFactoryImpl();
// Create Page Factory
PageFactory pageFactory = new PageFactoryImpl(objectFactory,
    storageManager, latchFactory);
// Create a Buffer Manager intance with a Buffer Pool of
// 50 pages and a hash table of 101 buckets
BufMgrImpl bufmgr = new BufMgrImpl(logmgr, pageFactory, 50, 101);
</pre>
<p>Note that when creating a Buffer Manager instance, you can set the
size of the Buffer Pool and also the size of the Hash table.</p>
<p>A Buffer Manager instance has a one to one relationship with a Page
Factory. Hence all pages managed by the Buffer Manager instance will
be of the same size; the page size is determined by the Page
Factory.</p>
</div>
<div class="section" id="fixing-pages-in-the-buffer-pool">
<h3><a class="toc-backref" href="#id93">Fixing Pages in the Buffer Pool</a></h3>
<p>The Buffer Manager provides methods for fixing pages in the Buffer
Pool. There are two possibilities:</p>
<ul class="simple">
<li>Fix a new page.</li>
<li>Fix an existing page.</li>
</ul>
<p>It is the client's responsibility to know whether the page is new or
existing. If a request is made to fix the page as new, then the
outcome may be unexpected. If the page already exists in the Buffer
Pool, it will be returned, rather than initializing a new Page.</p>
<p>When fixing a Page, the Page can be locked in one of three modes:</p>
<dl class="docutils">
<dt>Shared mode</dt>
<dd>allowing multiple clients to access the same Page concurrently
for reading.</dd>
<dt>Update mode</dt>
<dd>which allows one client to access the page in update mode,
but other clients may access the same page concurrently in
Shared mode.</dd>
<dt>Exclusive mode</dt>
<dd>in this mode only one client has access to the Page. This mode
is used when a client wishes to modify the contents of the Page.</dd>
</dl>
<p>An Update mode request can be upgraded to Exclusive mode. An
Exclusive mode request may be downgraded to an Update mode request.</p>
<p>Following code sample shows how page is fixed:</p>
<pre class="literal-block">
// Fix page as New (the second parameter). The page type is mypage.
// This page type should have been registered with the Object Registry
// prior to this call. The page will be latched in Exclusive mode.
// The last parameter is a hint for the LRU replacement algorithm.
BufferAccessBlock bab = bufmgr.fixExclusive(new PageId(1, 0),
  true, &quot;mypage&quot;, 0);
</pre>
<p>As shown above, when a page is fixed, the Buffer Manager returns a
BufferAccessBlock which contains a reference to the desired page.
The Page can be accessed as follows:</p>
<pre class="literal-block">
MyPage page = (MyPage) bab.getPage();
</pre>
</div>
<div class="section" id="modifying-page-contents">
<h3><a class="toc-backref" href="#id94">Modifying page contents</a></h3>
<p>Note that in order to modify a Page's content, the Page must be
fixed in Exclusive mode.</p>
<p>Also, the Write Ahead Log protocol must be obeyed. This requires the
modification to proceed as follows:</p>
<ol class="arabic simple">
<li>Fix the page in exclusive mode.</li>
<li>Generate a log record containing redo/undo information for
the modification about to be made.</li>
<li>Modify the page contents.</li>
<li>Set the Page LSN of the page and mark the page as dirty.</li>
<li>Unfix the page.</li>
</ol>
<p>Failure to follow this protocol may lead to unrecoverable changes.</p>
</div>
<div class="section" id="changing-lock-modes">
<h3><a class="toc-backref" href="#id95">Changing lock modes</a></h3>
<p>As mentioned before, pages that are locked in Update mode may be
upgraded to Exclusive mode. Pages that are locked in Exclusive mode
may be downgraded to Update mode. The BufferAccessBlock interface
provides methods that allow the lock mode to be upgraded or
downgraded.</p>
</div>
<div class="section" id="unfixing-a-page">
<h3><a class="toc-backref" href="#id96">Unfixing a Page</a></h3>
<p>It is very important to unfix a Page after the client is done with
it. Failure to do so may cause the Buffer Pool to become full and
the system will potentially come to a halt if further pages cannot
be fixed. A fixed page cannot be removed from the Buffer Pool.</p>
<p>It is also advisable to keep pages fixed for a short duration only.
If necessary the same page can be fixed again.</p>
</div>
</div>
</div>
<div class="section" id="transaction-manager">
<h1><a class="toc-backref" href="#id97">Transaction Manager</a></h1>
<div class="section" id="id10">
<h2><a class="toc-backref" href="#id98">Introduction</a></h2>
<p>The Transaction Manager is responsible for managing transactions. It
provides interfaces for starting new transactions, and for
committing or aborting transactions. The SimpleDBM implementation
also supports Savepoints. While the view seen by the user is simple,
the Transaction Manager is a complex module and has an elaborate
interface. This chapter will attempt to unravel the TM interface and
with the help of examples, demonstrate how this interface works and
how other modules can use this interface to participate in
Transactions.</p>
</div>
<div class="section" id="overiew">
<h2><a class="toc-backref" href="#id99">Overiew</a></h2>
<p>SimpleDBM's transaction manager is modelled after ARIES. It makes
following assumptions about the rest of the system:</p>
<ul class="simple">
<li>The system uses the Write Ahead Log protocol when making changes
to database containers.</li>
<li>The unit of change is a disk page. This means that logging is
on a per page basis.</li>
<li>The disk page contains a PageLSN field that can be used to track
the last log record that made changes to the page.</li>
<li>During checkpoints the Transaction Manager does not flush all
pages, instead it writes the Buffer Manager's <tt class="docutils literal"><span class="pre">table</span> <span class="pre">of</span> <span class="pre">contents''</span>
<span class="pre">to</span> <span class="pre">the</span> <span class="pre">Log.</span> <span class="pre">The</span> <span class="pre">table</span> <span class="pre">of</span> <span class="pre">contents</span> <span class="pre">is</span> <span class="pre">the</span> <span class="pre">list</span> <span class="pre">of</span> <span class="pre">dirty</span> <span class="pre">pages</span> <span class="pre">in</span>
<span class="pre">the</span> <span class="pre">Buffer</span> <span class="pre">Pool,</span> <span class="pre">along</span> <span class="pre">with</span> <span class="pre">their</span> <span class="pre">Recovery</span> <span class="pre">LSNs.</span> <span class="pre">The</span> <span class="pre">Recovery</span>
<span class="pre">LSN</span> <span class="pre">is</span> <span class="pre">the</span> <span class="pre">LSN</span> <span class="pre">of</span> <span class="pre">the</span> <span class="pre">oldest</span> <span class="pre">log</span> <span class="pre">record</span> <span class="pre">that</span> <span class="pre">could</span> <span class="pre">potentially</span>
<span class="pre">have</span> <span class="pre">have</span> <span class="pre">a</span> <span class="pre">change</span> <span class="pre">to</span> <span class="pre">the</span> <span class="pre">page.</span> <span class="pre">For</span> <span class="pre">a</span> <span class="pre">discussion</span> <span class="pre">of</span> <span class="pre">the</span> <span class="pre">Recovery</span>
<span class="pre">LSN</span> <span class="pre">please</span> <span class="pre">refer</span> <span class="pre">to</span> <span class="pre">Mohan's</span> <span class="pre">paper</span> <span class="pre">on</span> <span class="pre">ARIES</span> <span class="pre">and</span> <span class="pre">also</span> <span class="pre">to</span> <span class="pre">section</span>
<span class="pre">13.4.4.1</span> <span class="pre">of</span> <span class="pre">``Transaction</span> <span class="pre">Processing:</span> <span class="pre">Concepts</span> <span class="pre">and</span> <span class="pre">Techniques</span></tt>.
The TPCT book refers to Recovery LSNs as <tt class="docutils literal"><span class="pre">forminlsn</span></tt>.</li>
<li>At the end of system restart, the Transaction Manager informs
the Buffer Manager the RecoveryLSN status of all dirty pages;
the Buffer Manager must therefore provide an interface for
updating the Recovery LSN of such pages.</li>
<li>The Log Manager provides a mechanism for reliably recording
the Checkpoint LSN. Also, the Log Manager supports accessing
Log Records sequentially from a starting point, as well as
randomly using the LSN.</li>
<li>The Lock Manager provides an interface for acquiring and
release locks. The release mode must support a mechanism for
forcing the release of a lock.</li>
</ul>
</div>
<div class="section" id="what-is-aries">
<h2><a class="toc-backref" href="#id100">What is ARIES?</a></h2>
<p>ARIES is a Transaction Logging and Recovery algorithm developed at
IBM and published by IBM researcher C. Mohan.</p>
<p>For a full description of ARIES, please see <tt class="docutils literal"><span class="pre">Mohan,</span> <span class="pre">C.,</span>
<span class="pre">Haderle,</span> <span class="pre">D.,</span> <span class="pre">Lindsay,</span> <span class="pre">B.,</span> <span class="pre">Pirahesh,</span> <span class="pre">H.,</span> <span class="pre">Schwarz,</span> <span class="pre">P.</span> <span class="pre">ARIES:</span> <span class="pre">A</span>
<span class="pre">Transaction</span> <span class="pre">Recovery</span> <span class="pre">Method</span> <span class="pre">Supporting</span> <span class="pre">Fine-Granularity</span> <span class="pre">Locking</span> <span class="pre">and</span>
<span class="pre">Partial</span> <span class="pre">Rollbacks</span> <span class="pre">Using</span> <span class="pre">Write-Ahead</span> <span class="pre">Logging,</span> <span class="pre">ACM</span> <span class="pre">Transactions</span> <span class="pre">on</span>
<span class="pre">Database</span> <span class="pre">Systems,</span> <span class="pre">Vol.</span> <span class="pre">17,</span> <span class="pre">No.</span> <span class="pre">1,</span> <span class="pre">March</span> <span class="pre">1992,</span> <span class="pre">pp94-162.</span></tt></p>
<p>A brief overview of ARIES is given below.</p>
</div>
<div class="section" id="aries-an-overview">
<h2><a class="toc-backref" href="#id101">ARIES - An Overview</a></h2>
<p>Following is a brief description of the main principles behind
ARIES.</p>
<p>Firstly, in ARIES, changes always take the system forward. That is
to say, even transaction rollbacks are treated as if they are
updates to the system. This is counter-inituitive to what the user
thinks, because when a user asks for a transaction to be rolled
back, they assume that the system is going back to a previous state
of affairs. However, from the perspective of ARIES, there is no such
thing as going back. For example, if a transaction changes A to B
and then rolls back, ARIES treats the rollback as simply an update
that changes B to A. The forward change from A to B (redo) and the
reversal of B to A (undo) are both recorded as updates to the
system. Changes during normal operations are recorded as Redo-Undo
log records. As the name implies, these log records can be 'redone'
in case of a system crash, or 'undone' in case a rollback is
required. Changes made during rollbacks, however, are recorded as
Redo-only log records. These log records are called Compensation Log
Records (CLRs). The reason these are redo only is that by definition
a rollback does not need to be undone, whereas normal updates need
to be undone if the transaction decides to rollback.</p>
<p>The second basic principle of ARIES is that during recovery, history
is repeated. This can be explained as follows.</p>
<p>When a system crashes, there would be some transactions that have
completed (committed or aborted), and others that are still active.
The WAL protocol ensures that changes made by completed transactions
have been recorded in the Log. Changes made by incomplete
transactions may also be present in the Log, because Log Records are
created in the same order as the changes are made by the system.</p>
<p>During recovery, ARIES initially replays the Log to the bring the
system back to a state close to that when the crash occurred. This
means that ARIES replays the effects of not only those transactions
that committed or aborted, but also those that were active at the
time of the crash. Having brought the system to this state, ARIES
then identifies transactions that were incomplete, and rolls them
back. The basic idea is to repeat the entire history upto the point
of crash, and then undo failed transactions.</p>
<p>This approach has the advantage that during the redo phase, changes
can be replayed at a fairly low level, for example, the level of a
disk page. ARIES calls this page oriented redo. This feature is
significant because it means that until the redo phase is over, the
system does not need to know about higher level data structures such
as Indexes. Only during the undo phase, when incomplete transactions
are being rolled back, does the system need to know about high level
data structures.</p>
</div>
<div class="section" id="features-of-aries">
<h2><a class="toc-backref" href="#id102">Features of ARIES</a></h2>
<p>ARIES includes a number of optimisations to reduce the amount of
work required during normal operations and recovery.</p>
<p>One optimisation is to avoid application of log records
unnecessarily. The LSN of the most recently generated log record is
stored in each disk page. This is known as the PageLsn. The PageLsn
allows ARIES to determine during the redo phase, whether the changes
represented by a log record have been applied to the page or not.</p>
<p>ARIES chains log records for transactions in such a way that those
records that are no longer necessary, are skipped during recovery.
For example, if a transaction changed A to B, and then rolled back,
generating a log record for changing B to A, then during recovery,
ARIES would automatically skip the log record that represents the
change from A to B. This is made possible by maintaining a UndoLsn
pointer in every Log Record. The UndoLsn normally points to the
previous log record generated by the transaction. However, in log
records generated during Rollback (known as Compensation Log
Records), the UndoLsn is made to point to the Log record preceding
the one that is being undone. To take an example, let us assume that
a transaction generated log record 1, containing change from A to B,
then log record 2 containing change from B to C. At this point the
transaction decides to rollback the change from B to C. It therefore
generates a new log record 3, containing a change from C to B. The
UndoLsn of this log record is made to point at log record 1, instead
of log record 2. When following the UndoLsn chain, ARIES would skip
log record 2.</p>
<p>ARIES also supports efficient checkpoints. During a checkpoint, it
is not necessary to flush all database pages to disk. Instead ARIES
records a list of dirty buffer pages along with their
RecoveryLsn(s). The RecoveryLsn of a page is the LSN of the earliest
log record that represents a change to the page since it was read
from disk. By using this list, ARIES is able to determine during
recovery, where to start replaying the Log.</p>
<p>ARIES supports nested top-level action concept whereby part of a
transaction can be committed even if the transaction aborts. This is
useful for situations where a structural change should not be undone
even if the transaction aborts. Nested top level actions are
implemented using Dummy Compensation Log Records - and make use of
the ability to skip logs records using the UndoLsn pointer as
described previously.</p>
</div>
<div class="section" id="transactions-and-locks">
<h2><a class="toc-backref" href="#id103">Transactions and Locks</a></h2>
<p>There is close coordination between the Transaction Manager and the
Lock Manager. A Transaction needs to keep track of all locks
acquired on its behalf so that it can release them when the
Transaction completes. This is why the Transaction interface in
SimpleDBM provides methods for acquiring locks. If the Lock Manager
is invoked directly by the client then the TM has no way of knowing
which locks to release when the Transaction terminates.</p>
<p>While locks can be acquired by a client any time after a Transaction
starts, locks are released only on one of the following three
occasions:</p>
<ul class="simple">
<li>If the CURSOR STABILITY Isolation Mode is being used, then a
SHARED or UPDATE lock can be released once the cursor moves
to the next record. If REPEATABLE READ Isolation Mode is
used, then the UPDATE lock can be downgraded to SHARED lock
when the cursor moves. Note that the Transaction Manager does
not decide when to release or downgrade a lock; it is the
responsibility of the client to decide that. However, the
Transaction must update its record of the locks when this
happens. Therefore, lock release or downgrade requests
must be handled via the Transaction interface and not
directly between the client and the Lock Manager.</li>
<li>When a Transaction is rolled back to a Savepoint, any
locks acquired after the Savepoint are released. Note that
if a lock was acquired before the Savepoint, and upgraded
after the Savepoint, it will not be downgraded or released.
The Transaction interface manages the release of such locks.</li>
<li>Finally, when the Transaction completes, all locks held by
the transaction are released.</li>
</ul>
<p>Following sample code shows how a client interacts with the
Transaction.</p>
<pre class="literal-block">
// Start new Transaction
Transaction trx = trxmgr.begin();

// Acquire a shared lock
trx.acquireLock(new ObjectLock(1,15), LockMode.SHARED,
   LockDuration.MANUAL_DURATION);

// Upgrade the shared lock
trx.acquireLock(new ObjectLock(1,15), LockMode.UPDATE,
LockDuration.MANUAL_DURATION);

// Downgrade the update lock
trx.downgradeLock(new ObjectLock(1, 15),
   LockMode.SHARED);

// commit the transaction, releasing all locks
trx.commit();
</pre>
</div>
<div class="section" id="transactions-and-modules">
<h2><a class="toc-backref" href="#id104">Transactions and Modules</a></h2>
<p>The Transaction Manager provides a framework for managing
transactions. It provides interfaces to:</p>
<ol class="arabic simple">
<li>Start and end transactions</li>
<li>Acquire locks on behalf of transactions</li>
<li>Create log records on behalf of transactions.</li>
</ol>
<p>The Transaction Manager itself does not initiate changes to database
pages, though it may coordinate the redo or undo of such changes --
changes are always initiated by clients. A client in this context is
some module within the system that wishes to make changes to the
database disk pages as part of a Transaction.</p>
<p>The Transaction Manager does not know in advance what clients it may
have to interact with. However, it needs to be able to call upon the
clients to redo or undo the effects of log records when required.
This is enabled in two ways:</p>
<ol class="arabic simple">
<li>Firstly, all clients must implement the TransactionalModule
interface. This interface defines the operations that the
Transaction Manager may call upon the client to perform.</li>
<li>Secondly, all modules must <em>register</em> themselves to the
Transaction Manager using unique Module IDs. This way, the
Transaction Manager knows how to obtain access to a module,
and ask it to perform an action.</li>
<li>Finally, all log records generated by a Module need to be
tagged with the Module's Unique ID. If this is not done,
the Transaction Manager would not know which module is
responsible for handling a particular log record.</li>
</ol>
</div>
<div class="section" id="transactions-and-log-records">
<h2><a class="toc-backref" href="#id105">Transactions and Log records</a></h2>
<p>The Transaction Manager works very closely with the Log Manager to
ensure the ACID properties of transactions. We saw in the chapter on
Log Manager that it does not care about the contents of Log Records.
The Transaction Manager, however, does care, and defines a hierarchy
of different Log record types that should be used by clients. This
is explained below.</p>
</div>
<div class="section" id="the-loggable-hierarchy">
<h2><a class="toc-backref" href="#id106">The Loggable hierarchy</a></h2>
<p>Loggable is parent interface for all Log Records. The Transaction
Manager will only accept Log records that implement this interface.
This can be seen from the signature of the logInsert() method
provided by the Transaction interface.</p>
<p>The Loggable hierarchy defines the various types of log records that
clients can generate. These are further discussed below.</p>
<div class="section" id="loggable-hierarchy">
<h3><a class="toc-backref" href="#id107">Loggable Hierarchy</a></h3>
<p>The main branches of the Loggable hierarchy are shown below. Note
that some of the hierarchy is not visible to outside clients (marked
as internal).</p>
<table border="1" class="docutils">
<caption>Loggable Hierarchy</caption>
<colgroup>
<col width="42%" />
<col width="58%" />
</colgroup>
<tbody valign="top">
<tr><td>Interface</td>
<td>Description</td>
</tr>
<tr><td>Redoable</td>
<td>All log operations that affect database
pages must implement this interface or one
of its sub-interfaces. The Transaction
Manager expects a valid PageId (s) to be
returned by a Redoable log record. Note
that Compensation and Undoable log records
are sub-interfaces of Redoable.</td>
</tr>
<tr><td>NonTransactionRelatedOperation</td>
<td>These represent changes that are not
related to specific pages. Since the ARIES
algorithm uses page LSNs to track updates
caused by log records, changes made by
this type of log record are not tracked
they are repeated unconditionally at
system start. At present, this type of log
operation is used to handle opening of
containers.</td>
</tr>
<tr><td>PostCommitAction</td>
<td>Although PostCommitAction is a
subinterface of
NonTransactionRelatedOperation at present,
this may change in
future. PostCommitActions are used to
schedule actions that must be performed
after a successful commit. An example of
such an action is the dropping of a
container. To avoid logging the full
contents of the container, the actual
delete of the container must be deferred
until it is certain that the Transaction
is committing.  Note that unlike other
NonTransactionRelatedOperations, the
Transaction Manager does track the status
of PostCommitActions and will execute them
at restart if they have not been executed.</td>
</tr>
<tr><td>ContainerDeleteOperation</td>
<td>The Transaction Manager needs to be aware
when containers are deleted, both when a
container is dropped or when the creation
of a container is aborted. In both cases,
the TM uses this marker interface to
identify the delete operation and
coordinates with the Buffer Manager to
clear the cached pages related to the
deleted container.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="transaction-manager-internal-log-records">
<h3><a class="toc-backref" href="#id108">Transaction Manager Internal Log Records</a></h3>
<p>The Transaction Manager uses internal log records to track
Transaction completion, and also Checkpoints. These log record types
are not available outside the implementation of the TM.</p>
</div>
<div class="section" id="redoable">
<h3><a class="toc-backref" href="#id109">Redoable</a></h3>
<p>Generally speaking, most log records are implementations of Redoable
interface or one of its sub-interfaces. A Redoable log record is
related to one or more database pages, and can be re-done at System
restart. In some cases, the effects of a log record should not be
undone; such records are called Redo-only log records and can be
created in a number of ways:</p>
<ul class="simple">
<li>Implement the Redoable interface but not its Undoable sub-interface.</li>
<li>Implement the Compensation interface. This is a special case,
which is discussed later.</li>
</ul>
<p>An example of a Redo-only log record is the Page Format operation.
Newly created pages need to be formatted, but once this is done, it
is unnecessary to undo the formatting.</p>
<p>Given below is an example implementation of a Page Format log
record:</p>
<pre class="literal-block">
public static class FormatRawPage extends BaseLoggable
  implements Redoable, PageFormatOperation {

  ByteString dataPageType;

  &#64;Override
  public void init() {
  }

  public final String getDataPageType() {
      return dataPageType.toString();
  }

  public final void setDataPageType(String dataPageType) {
      this.dataPageType = new ByteString(dataPageType);
  }

  &#64;Override
  public int getStoredLength() {
      return super.getStoredLength() +
          dataPageType.getStoredLength();
  }

  &#64;Override
  public void retrieve(ByteBuffer bb) {
      super.retrieve(bb);
      dataPageType = new ByteString();
      dataPageType.retrieve(bb);
  }

  &#64;Override
  public void store(ByteBuffer bb) {
      super.store(bb);
      dataPageType.store(bb);
  }
}
</pre>
<p>As astute reader will notice that the Page Format operation extends
the BaseLoggable class and implements both Redoable and
PageFormatOperation interfaces. The BaseLoggable class and the
PageFormatOperation interface are described further below.</p>
</div>
<div class="section" id="baseloggable-abstract-class">
<h3><a class="toc-backref" href="#id110">BaseLoggable abstract class</a></h3>
<p>The Transaction Manager provides the BaseLoggable abstract class
which implements the Loggable interface. Rather than attempting to
implement the Loggable interface from scratch, it is highly
recommended that clients sub-class the BaseLoggable class and extend
it to add functionality. The reason for making Loggable an interface
and not an abstract class like BaseLoggable is that it allows the
client to implement its own class hierarchy independently from the
Loggable hierarchy.</p>
</div>
<div class="section" id="pageformatoperation">
<h3><a class="toc-backref" href="#id111">PageFormatOperation</a></h3>
<p>Operations that format new pages are particularly important because
the Transaction Manager must invoke the Buffer Manager FIX AS NEW
interface to fix pages affected by them. If the normal fix interface
is called, an exception will be thrown because the page may not
exist on disk or may be garbage. To allow the Transaction Manager to
spot page format operations, all log records that perform such
actions should implement the PageFormatOperation interface. This is
a marker interface only.</p>
<p>Usually, PageFormatOperations are redo-only.</p>
<p>In SimpleDBM, the page format operations are handled when a
container is created or expanded.</p>
</div>
<div class="section" id="multipageredo">
<h3><a class="toc-backref" href="#id112">MultiPageRedo</a></h3>
<p>Normally a Redoable log record represents changes to a single page.
Sometimes, however, it may be necessary for a single log record to
contain changes made to multiple pages. In such cases, the Log
record should implement the MultiPageRedo interface.</p>
<p>Note that clients need to follow the following procedure when
creating MultiPageRedo log records.</p>
<ol class="arabic simple">
<li>Fix all the affected pages.</li>
<li>Generate the MultiPageRedo log record.</li>
<li>Apply changes to the affected pages.</li>
<li>Set the pageLsn of all affected pages to the LSN of the
log record.</li>
<li>Unfix all affected pages.</li>
</ol>
</div>
<div class="section" id="undoable">
<h3><a class="toc-backref" href="#id113">Undoable</a></h3>
<p>Logs records that need to be undoable should implement the Undoable
interface. The Undoable interface extends the Redoable interface,
thus, undoable log records are by definition redoable as well.</p>
<p>An Undoable log record should contain data that can be used to
<em>redo</em> the changes, as well as to <em>undo</em> the changes. Typically,
this means that both old and new values must be stored. For example,
if the log is to represent changing a field value from A to B, then
its old value will be A, and new value will be B.</p>
<p>At system restart, Undoable records are redone. This means that the
redo portion of such log records are applied. In the example given
above, this would cause the field value to be set to B.</p>
<p>When the Transaction Manager needs to undo the changes represented
by an Undoable record, it will ask the client to perform one of
following depending upon the type of Undoable record:</p>
<ul class="simple">
<li>If the Undoable record is an instance of SinglePageLogicalUndo,
then the Transaction Manager assumes that the undo operation
must be performed against some page other than the one
originally affected. However, the undo is known to affect only
one page. In this situation the Transaction Manager requests
the client to identify the page to which undo should be applied,
and then coordinates the generation of undo as normal.</li>
<li>If the Undoable record is an instance of LogicalUndo, then the
Transaction Manager assumes that the undo operation is not an
exact inverse of the redo operation and may require updates
to one or more pages. It also assumes that the client may
generate additional log records. For such log records, the
client is given full control over how the undo is to be
performed.</li>
<li>If neither of above are true, then the Transaction Manager
assumes that the Undo operation is <em>physical</em>, i.e., it is to
be applied to the same page that was affected by the original
change. In this case, it requests the client to generate the
undo information (Compensation) which is then applied as a
redo operation.</li>
</ul>
<p>Following sections describe above in reverse order.</p>
</div>
<div class="section" id="physical-undos">
<h3><a class="toc-backref" href="#id114">Physical Undos</a></h3>
<p>The simplest case is that of a Physical Undo, where the undo
operation affects the same page that was originally modified during
forward change (i.e., redo). In this case, the Transaction Manager
asks the client to generate a Compensation record for redoing the
undo operation. This is then applied to the affected page using the
redo interface provided by the client. Following code shows how the
Transaction Manager interacts with the client:</p>
<pre class="literal-block">
Compensation clr = module.generateCompensation(undoable);
....
module.redo(page, clr);
</pre>
<p>Thus, for this type of log record, the client must implement the
generateCompensation(Undoable) and redo(Page, Redoable) operations.</p>
</div>
<div class="section" id="singlepagelogicalundos">
<h3><a class="toc-backref" href="#id115">SinglePageLogicalUndos</a></h3>
<p>SinglePageLogicalUndos are slightly more complex than Physical
undos. The undo operation is guaranteed to affect one page only, but
it may not be the page originally affected. To handle this scenario,
the Transaction Manager first asks the client to identify the page
where the undo is to be applied. Once this has been done, the
process is identical to that of Physical undos. Following code
extract shows how the TM interacts with the client:</p>
<pre class="literal-block">
BufferAccessBlock bab = module.findAndFixPageForUndo(undoable);
...
Compensation clr = module.generateCompensation(undoable);
...
module.redo(bab.getPage(), clr);
...
bab.unfix();
</pre>
<p>What above shows is that the client is responsible for identifying
and fixing the appropriate page -- the page is unfixed by
Transaction Manager once the change has been applied.</p>
</div>
<div class="section" id="logicalundos">
<h3><a class="toc-backref" href="#id116">LogicalUndos</a></h3>
<p>From the client's perspective the most complex type of undo is where
the undo operation may impact several pages, and may result in
additional log records being generated.</p>
<p>For such records, the Transaction Manager simply invokes the
client's undo interface as follows:</p>
<pre class="literal-block">
module.undo(trx, undoable)
</pre>
<p>It is the client's responsibility to generate appropriate log
records and make changes to database pages.</p>
</div>
<div class="section" id="comments-about-implementing-undo-operations">
<h3><a class="toc-backref" href="#id117">Comments about implementing undo operations</a></h3>
<p>From the discussion above, it should be clear that Physical undos
are the easiest to implement. They are also the most efficient.
However, in some cases, notably in Index operations, physical undos
may not be optimum. This is because in a BTree Index, a key can move from
one page to another as a result of page splits or page merges.</p>
<p>In some BTree implementations, such as in Apache Derby, the undo
operations are limited to a single page. This is achieved through
the use of <em>logical key deletes</em>.</p>
<p>Where keys are physically deleted, undo of key deletes may cause
page splits. Such undo operations may impact more than one page. The
SimpleDBM BTree implementation is an example of this type of
operation.</p>
</div>
<div class="section" id="compensation-records">
<h3><a class="toc-backref" href="#id118">Compensation records</a></h3>
<p>Undo operations are represented using Compensation log records. The
benefits of using Compensation log records are explained in detail
by Mohan in the ARIES paper. As Mohan explains in his paper, a
Compensation record is redo-only -- it is never undone. A unique
property of ARIES algorithm is that Compensation log records are
linked back to the predecessor of the log record that is being
undone. This backward chaining allows ARIES to skip processing of
undo operations that are already applied.</p>
<p>While Compensation log records are mostly used to represent undo
operations, sometimes, they can be effectively used to represent
redo operations as well. The system can make use of the backward
chaining to allow certain log records to be skipped in the event of
an undo. This feature is the basis for the Nested Top Action concept
in ARIES. It is also exploited by the SimpleDBM BTree implementation
to reduce the amount of logging required for structure modification
operations. For further details, please refer to the paper entitled
-- <tt class="docutils literal"><span class="pre">Space</span> <span class="pre">Management</span> <span class="pre">issues</span> <span class="pre">in</span> <span class="pre">B-Link</span> <span class="pre">trees</span></tt>.</p>
</div>
<div class="section" id="nontransactionrelatedoperations">
<h3><a class="toc-backref" href="#id119">NonTransactionRelatedOperations</a></h3>
<p>A NonTransactionRelatedOperation is one that should be redone
without reference to a database page. Note that such operations are
discarded after a Checkpoint, i.e, only those records will be redone
that are encountered after the last Checkpoint. Is is therefore
important to ensure that the effect of these log records are also
saved in Checkpoint operations.</p>
<p>In SimpleDBM, the only use of this operation at present is to log
opening of containers. After a container is created, a
NonTransactionRelatedOperation is logged to ensure that the
container will be reopened at system restart. A Checkpoint operation
in SimpleDBM includes a list of all open containers, hence, any past
open container log records become redundant after the Checkpoint.</p>
</div>
<div class="section" id="postcommitactions">
<h3><a class="toc-backref" href="#id120">PostCommitActions</a></h3>
<p>PostCommitActions are used to defer certain actions until it is
known for sure that the Transaction is definitely committing. In
SimpleDBM, dropping a container is handled this way. When a request
is made by a client to drop a container, a PostCommitAction is
scheduled to occur once the transaction commits.</p>
<p>The Transaction Manager tracks the status of PostCommitActions and
ensures that once a transaction has committed, its PostCommitActions
are executed even if there is a system crash. This is achieved by
logging such actions as part of the transaction's Prepare log
record. Note that a PostCommitAction may be executed more than once
by the TransactionManager, hence it should be coded in such a way
that there is no adverse impact if the operation is repeated. For
example, if the action is to delete a container, it would be
erroneous for the PostCommitAction to complain if the container is
already deleted.</p>
</div>
<div class="section" id="containerdeleteoperations">
<h3><a class="toc-backref" href="#id121">ContainerDeleteOperations</a></h3>
<p>Since an ARIES style Transaction Manager operates at the level of
disk pages, it is necessary to know when a container has been
deleted so that all pages related to the container can be marked
invalid. Also, the container needs to be closed to prevent further
changes to it. The Transaction Manager uses the
ContainerDeleteOperation interface as a marker interface to identify
log records that are going to cause containers to be dropped.</p>
</div>
</div>
</div>
<div class="section" id="space-manager">
<h1><a class="toc-backref" href="#id122">Space Manager</a></h1>
<div class="section" id="id11">
<h2><a class="toc-backref" href="#id123">Introduction</a></h2>
<p>The Space Manager module is responsible for managing free space
information within a Storage Container. Using free space
information, the Space Manager module can find pages that meet space
requirements of clients. The Space Manager module also handles
creation of new containers and expansion/deletion of existing
containers.</p>
</div>
<div class="section" id="comparison-with-storage-manager-module">
<h2><a class="toc-backref" href="#id124">Comparison with Storage Manager module</a></h2>
<p>We have previously encountered the Storage Manager module which
provides facilities for creating and dropping specific containers.
However, these operations are low-level, and not transactional.
Containers created by the Storage Manager module are raw, and do not
have any structure.</p>
<p>The Space Manager module implements a higher level interface. It
differs from the Storage Manager module in following ways:</p>
<ul class="simple">
<li>Its operations are transactional.</li>
<li>Containers have a predefined structure and support fixed-size
pages.</li>
<li>The Space Manager module implements special pages within the
container where information about other pages is maintained.
This information can be used to quickly locate a page with
specified amount of storage.</li>
</ul>
</div>
<div class="section" id="id12">
<h2><a class="toc-backref" href="#id125">Operations</a></h2>
<div class="section" id="obtaining-an-instance-of-spacemgr">
<h3><a class="toc-backref" href="#id126">Obtaining an instance of SpaceMgr</a></h3>
<p>The default implementation of the SpaceMgr module is
org.simpledbm.rss.sm.impl.SpaceMgrImpl.
As can be seen in the example below, the SpaceMgr module depends
upon a number of other modules.</p>
<pre class="literal-block">
SpaceMgr spacemgr = new SpaceMgrImpl(objectFactory, pageFactory,
  logmgr, bufmgr, storageManager, storageFactory,
  loggableFactory, trxmgr, moduleRegistry);
</pre>
</div>
<div class="section" id="creating-a-container">
<h3><a class="toc-backref" href="#id127">Creating a Container</a></h3>
<p>Following sample code demonstrates how to create a Container. Note
that for correct operation, the container ID allocated to the new
container should be locked exclusively prior to creating the
container. This will prevent other transactions from manipulating
the same container.</p>
<pre class="literal-block">
SpaceMgr spacemgr = new SpaceMgrImpl(...);
Transaction trx = trxmgr.begin();
boolean okay = false;
try {
  // Create a new Container named testctr.dat and assign it a container
  // ID of 1. This container will use RawPages as its data page.

  int containerId = 1;
  int spaceBits = 1;
  int extentSize = 64;
  spacemgr.createContainer(trx, &quot;testctr.dat&quot;, containerId,
     spaceBits, extentSize, pageFactory.getRawPageType());

  okay = true;
}
finally {
  if (okay) {
     trx.commit();
  }
  else {
     trx.abort();
  }
}
</pre>
<p>Note that the container create operation is transactional.</p>
</div>
<div class="section" id="extending-a-container">
<h3><a class="toc-backref" href="#id128">Extending a Container</a></h3>
<p>When a container is initially created, it is allocated an extent of
specified size. The extent is the minimum allocation unit for a
container; a container is always expanded in extents.</p>
<pre class="literal-block">
Transaction trx = trxmgr.begin();
spacemgr.extendContainer(trx, 1);
trx.commit();
</pre>
</div>
<div class="section" id="deleting-a-container">
<h3><a class="toc-backref" href="#id129">Deleting a container</a></h3>
<p>Note that prior to deleting a container, you must acquire an
Exclusive lock on the container ID. This will prevent other transactions
from accessing the same container.</p>
<p>Deleting a container is as simple an operation as extending it:</p>
<pre class="literal-block">
Transaction trx = trxmgr.begin();
spacemgr.dropContainer(trx, 1);
trx.commit();
</pre>
<p>An important point to note about the container delete operation
is that the physical removal of the container is deferred until
the transaction commits. This is done to allow the delete operation
to be rolled back in case the transaction aborts.</p>
<p>A limitation in the current implementation is that the container
is not physically removed. This will be fixed in a future revision
of the module.</p>
</div>
<div class="section" id="searching-for-free-space">
<h3><a class="toc-backref" href="#id130">Searching for free space</a></h3>
<p>At the time of creating a container, you can specify the number
of bits that should be used to track space information for each
individual page. At present, you can either use a single
bit or two bits. If one bit is used, the possible values are
0 and 1, if two bits are used, then the possible values are 0,
1,2 and 3. The SpaceMgr module initializes the space bits with a
value of 0, hence this value always means unused or unallocated
space. The interpretation of other values is upto the client;
SpaceMgr merely provides the mechanism to maintain
this data.</p>
<p>As an example, in the BTree module, containers are created with
a single bit for each page. The value 0 is used to identify
unallocated pages, 1 is used for allocated pages.</p>
<p>In order to search for free space, you first need to obtain
a SpaceCursor. The SpaceCursor mechanism allows you to perform
following actions:</p>
<ul class="simple">
<li>Search for page with specified space usage, and fix
associated space map page exclusively.</li>
<li>Update the space map information for a page, and log this
operation.</li>
<li>Fix a specific space map page.</li>
<li>Unfix the currently fixed space map page.</li>
</ul>
<p>When you search for free space, you need to provide an implementation
of <tt class="docutils literal"><span class="pre">SpaceChecker</span></tt>; this will be invoked by SpaceMgr module to
check whether a page meets the space requirements of the client.</p>
<p>Here is an example of a search that attempts to locate pages that
are unallocated:</p>
<pre class="literal-block">
int pageNumber = spaceCursor.
     findAndFixSpaceMapPageExclusively(new SpaceChecker() {
  public boolean hasSpace(int value) {
     return value == 0;
  }
});
</pre>
<p>If the SpaceCursor cannot locate a suitable page, it returns -1. Otherwise it
returns the page that satisfied the space request.</p>
<p>An important point to note is that just because space map information
indicates that the page has free space, does not always mean that the page
will be able to satisfy the request. Some modules, such as the TupleMgr
module, may mark pages as free even though they are still occupied.
Please refer to the TupleMgr documentation to understand why this is
so. In general, it is upto the client module to ensure that the space
map information is accurate and up-to-date.</p>
<p>Usually, if the space map search returns -1, the container needs to be
extended and then the search retried.</p>
</div>
<div class="section" id="updating-space-information">
<h3><a class="toc-backref" href="#id131">Updating space information</a></h3>
<p>A successful search will result in the space map page being erxclusively
latched. Hence, after the search, the client must unfix the page. Failure
to do so will cause pages to remain fixed and exhaust the Buffer Pool.
The SpaceCursor interface provides an interface for unfixing the
currently fixed space map page.</p>
<pre class="literal-block">
Transaction trx = trxmgr.begin();
spaceCursor.updateAndLogRedoOnly(trx, pageNumber, 1);
spaceCursor.unfixCurrentSpaceMapPage();
trx.commit();
</pre>
<p>Above example also shows how to update the space map page information
and also log it to the Write Ahead Log.</p>
<p>There will be times when the client wishes to update the space
information for a specific page. In this situation it is the client's
responsibility to know which space map page contains the associated
data.</p>
<p>The SpaceCursor interface supports accessing a specific space
map page, provided it is known which page is desired:</p>
<pre class="literal-block">
Transaction trx = trxmgr.begin();
SpaceCursor spcursor = spaceMgr.getSpaceCursor(containerId);
spcursor.fixSpaceMapPageExclusively(spaceMapPageNumber,
  pageNumber);
try {
  pcursor.updateAndLogRedoOnly(trx, pageNumber, spacebits);
} finally {
  spcursor.unfixCurrentSpaceMapPage();
}
trx.commit();
</pre>
</div>
</div>
</div>
<div class="section" id="slotted-page-manager">
<h1><a class="toc-backref" href="#id132">Slotted Page Manager</a></h1>
<div class="section" id="id13">
<h2><a class="toc-backref" href="#id133">Introduction</a></h2>
<p>SimpleDBM, like most other databases, stores records in fixed size
pages. The Slotted Page Manager module provides an enhancement to
the Raw Page by allowing records to be inserted, updated and deleted
within the page. By providing a common infrastructure, client
modules such as the B-Tree Manager or the Tuple Manager can
concentrate on higher level functions.</p>
</div>
<div class="section" id="structure-of-slotted-page">
<h2><a class="toc-backref" href="#id134">Structure of Slotted Page</a></h2>
<p>From the client perspective, the structure of the Slotted Page is
not relevant in its details. What matters is the interface. A key
requirement is to be able to access records quickly within the page,
using a numeric identifier called Slot Number.</p>
<p>Each record in the page is assigned a Slot Number. Slot Numbers
start from 0, ie, the first record in the page can be accessed via
Slot Number 0.</p>
<p>In addition to storing the record data, each Slot is also capable of
storing a set of flags in a Short integer. The interpretation of
these flags is up to the client module.</p>
<p>Records may be inserted at a specific Slot position, updated and
deleted. Deleted records leave the Slot unoccupied, but do not shift
records. A purge interface is available which completely removes the
record specified and also shifts to the left all records to the right of
the purged record.</p>
</div>
<div class="section" id="obtaining-instances-of-slotted-page">
<h2><a class="toc-backref" href="#id135">Obtaining instances of Slotted Page</a></h2>
<p>The actual implementation of the Slotted Page is not visible to the
outside world. The Slotted Page Manager module <em>registers</em> the
implementation of SlottedPage to the Object Registry. This enables
client modules to obtain new instances of SlottedPage without having
to know how this is implemented. Following snippet of code
illustrates this:</p>
<pre class="literal-block">
SlottedPageMgr spmgr = new SlottedPageMgrImpl(objectFactory);
SlottedPage page = (SlottedPage)
  pageFactory.getInstance(spmgr.getPageType(), new PageId());
</pre>
<p>Note that the PageFactory is able to instantiate the appropriate
Page type using the typecode (<tt class="docutils literal"><span class="pre">spmgr.getPageType()</span></tt>) assigned
to the implementation by the SlottedPageManager module.</p>
<p>In most cases, clients do not actually invoke the PageFactory as
shown above. Instead it is more common to specify the page type when
a container is first created; this ensures that the Buffer Manager
module can instantiate the correct page type automatically. Here is
an example of how to do this:</p>
<pre class="literal-block">
// Create the container and specify SlottedPage as the page
// type.
spaceMgr.createContainer(trx, name, containerId, spacebits,
  extentSize, spmgr.getPageType());

// Fix page 5
BufferAccessBlock bab =
  bufmgr.fixExclusive(new PageId(containerId, 5), false, -1, 0);

// Get access to the page.
SlottedPage page = (SlottedPage) bab.getPage();
</pre>
<p>In the example above, the Space Manager module formats all data
pages in the specified container as SlottedPage. This ensures that
when the client module accesses the page via the Buffer Manager,
the correct page type is automatically instantiated.</p>
</div>
<div class="section" id="inserting-or-updating-records">
<h2><a class="toc-backref" href="#id136">Inserting or updating records</a></h2>
<p>The SlottedPage interface supports two insert modes. In the
replace mode, the new record will replace any existing record at
the same Slot. If replace mode is false, the new record will cause
existing records to be shifted to the right to make space for the
new record.</p>
<pre class="literal-block">
boolean replaceMode = false;
// Insert item1 at Slot 0
page.insertAt(0, item1, replaceMode);
// Insert item0 at Slot 0
page.insertAt(0, item0, replaceMode);
// Now item1 is at Slot 1
</pre>
<p>When invoking <tt class="docutils literal"><span class="pre">SlottedPage.insertAt()</span></tt>, the SlotNumber must be
between 0 and <tt class="docutils literal"><span class="pre">SlottedPage.getNumberOfSlots()</span></tt>.</p>
</div>
<div class="section" id="deleting-records">
<h2><a class="toc-backref" href="#id137">Deleting records</a></h2>
<p>As mentioned before, there are two types of delete.
The first type removes the record but does not disturb the
Slot Numbers. Example:</p>
<pre class="literal-block">
// Insert at slot 0
page.insertAt(0, item0, true);
// Insert at slot 1
page.insertAt(1, item1, true);
// Delete slot 0
page.delete(0)
// Slot 1 still holds item1
</pre>
<p>The second mode is called purge, and in this mode,
records to the right of the deleted Slot are moved
left to fill up the hole. Example:</p>
<pre class="literal-block">
// Insert at slot 0
page.insertAt(0, item0, true);
// Insert at slot 1
page.insertAt(1, item1, true);
// Delete slot 0
page.purge(0)
// Slot 0 now holds item1
</pre>
</div>
<div class="section" id="accessing-records">
<h2><a class="toc-backref" href="#id138">Accessing records</a></h2>
<p>The <tt class="docutils literal"><span class="pre">SlottedPage.getNumberOfSlots()</span></tt> method returns the number
of slots in the page. To access a slot, you invoke <tt class="docutils literal"><span class="pre">SlottedPage.get()</span></tt>;
you must supply the correct <tt class="docutils literal"><span class="pre">Storable</span></tt> object
type as the second parameter.</p>
<pre class="literal-block">
// Get the record at Slot 1 as a StringItem.
page.get(1, new StringItem());
</pre>
</div>
<div class="section" id="miscellaneous-operations">
<h2><a class="toc-backref" href="#id139">Miscellaneous operations</a></h2>
<p>It is possible to assign to each Slot a set of flags.
Upto 16 bits can be accomodated.</p>
<pre class="literal-block">
// Get the flags for Slot 0
int flags = page.getFlags(0);
// Update the flags for Slot 0
page.setFlags(0, (short)(flags | 1));
</pre>
<p>The total number of Slots in the page is returned by
the method <tt class="docutils literal"><span class="pre">getNumberOfSlots()</span></tt>. To test whether a particular Slot is deleted, you can use
the method <tt class="docutils literal"><span class="pre">isSlotDeleted()</span></tt>.
There are a few methods that provide space usage data.</p>
</div>
</div>
<div class="section" id="index-manager">
<h1><a class="toc-backref" href="#id140">Index Manager</a></h1>
<div class="section" id="id14">
<h2><a class="toc-backref" href="#id141">Overview</a></h2>
<p>The Index Manager module is responsible for implementing search structures
such as BTrees. Indexes are used to enforce primary key constraint and unique
constraints in tables, as well as for ensuring speedy retrieval of data.</p>
<p>SimpleDBM currently provides a B-Link Tree Index implementation. The
implementation is based upon algorithms described in:</p>
<blockquote>
Ibrahim Jaluta, Seppo Sippu and Eljas Soisalon-Soininen. Concurrency control
and recovery for balanced B-link trees. The VLDB Journal, Volume 14, Issue 2
(April 2005), Pages: 257 - 277, ISSN:1066-8888.</blockquote>
<p>There are some variations from the published algorithms, noted at appropriate
places within the code.</p>
</div>
<div class="section" id="structure-of-the-b-link-tree">
<h2><a class="toc-backref" href="#id142">Structure of the B-link Tree</a></h2>
<p>The tree is contained in a container of fixed size pages. The
first page (pagenumber = 0) of the container is a header page. The second
page (pagenumber = 1) is the first space map page. The third page
(pagenumber = 2) is always allocated as the root page of the tree.
The root page never changes.</p>
<p>Pages at all levels are linked to their right siblings. Although
there is a pointer to the left sibling, this is currently not
implemented.</p>
<p>In leaf pages, an extra item called the high key is present. In index
pages, the last key acts as the highkey. All keys in a page are guaranteed
to be &lt;= than the highkey. Note that in leaf pages the highkey may not be
the same as the last key in the page.</p>
<p>In index pages, each key contains a pointer to a child page. The child
page contains keys &lt;= to the key in the index page. The highkey of the
child page will match the index key if the child is a direct child.
The highkey of the child page will be &lt; than the index key if the
child has a sibling that is an indirect child.</p>
<p>All pages other than root must have at least two items (excluding
highkey in leaf pages).</p>
<p>The rightmost key at any level is a special key containing logical
INFINITY. Initially, the empty tree contains this key only. As the tree
grows through splitting of pages, the INFINITY key is carried
forward to the rightmost pages at each level of the tree. This key can
never be deleted from the tree.</p>
</div>
<div class="section" id="structure-of-nodes">
<h2><a class="toc-backref" href="#id143">Structure of Nodes</a></h2>
<div class="section" id="leaf-nodes">
<h3><a class="toc-backref" href="#id144">Leaf Nodes</a></h3>
<p>Leaf nodes have following structure:</p>
<pre class="literal-block">
[header] [item1] [item2] ... [itemN] [highkey]

item[0] = header
item[1,header.KeyCount-1] = keys
item[header.keyCount] = high key
</pre>
<p>The highkey in a leaf node is an extra item, and may or may not be
the same as the last key [itemN] in the page. Operations that change the
highkey in leaf pages are Split, Merge and Redistribute. All keys in the
page are guaranteed to be &lt;= highkey.</p>
</div>
<div class="section" id="index-nodes">
<h3><a class="toc-backref" href="#id145">Index Nodes</a></h3>
<p>Index nodes have following structure:</p>
<pre class="literal-block">
[header] [item1] [item2] ... [itemN]
item[0] = header
item[1,header.KeyCount] = keys
</pre>
<p>The last key is also the highkey.
Note that the rightmost index page at any level has a special
key as the highkey - this key has a value of INFINITY.</p>
<p>Each item in an index key contains a pointer to a child page.
The child page contains keys that are &lt;=
than the item key.</p>
</div>
</div>
<div class="section" id="key-differences-from-published-algorithm">
<h2><a class="toc-backref" href="#id146">Key Differences from published algorithm</a></h2>
<div class="section" id="page-split-operation">
<h3><a class="toc-backref" href="#id147">Page Split operation</a></h3>
<p>This differs from the published algorithm in following ways:</p>
<ol class="arabic simple">
<li>Page allocation is logged as redo-undo.</li>
<li>Space map page latch is released prior to any other exclusive latch.</li>
<li>The split is logged as Muli Page Compensation record, with undoNextLsn
set to the LSN prior to the page allocation log record.</li>
<li>Information about space map page is stored in new page.</li>
</ol>
</div>
<div class="section" id="merge-operation">
<h3><a class="toc-backref" href="#id148">Merge Operation</a></h3>
<p>This algorithm differs from published algorithm in its management of
space map update. In the interests of high concurrency, the space map
page update is handled as a separate redo only action.</p>
<p>If this space map update log record does not survive a system crash,
then the page will end up appearing allocated. However the actual page will
be marked as deallocated, and hence can be reclaimed later on, although
this is not implemented.</p>
<p>The Merge Operation is logged as a Multi-Page Redo only record.</p>
</div>
<div class="section" id="link-operation">
<h3><a class="toc-backref" href="#id149">Link Operation</a></h3>
<p>This algorithm differs slightly from the published algorithm.
The psuedo code is shown below.</p>
<pre class="literal-block">
v = highkey of R
u = highkey of Q
Link(P, Q, R) {
  upgrade-latch(P);
  change the index record (v, Q.pageno) to (v, R.pageno);
  insert the index record (u, Q.pageno) before (v, R.pageno);
  lsn = log(&lt;unlink, P, Q.pageno, R.pageno&gt;);
  P.pageLsn = lsn;
  downgrade-latch(P);
}
</pre>
</div>
<div class="section" id="unlink-operation">
<h3><a class="toc-backref" href="#id150">Unlink Operation</a></h3>
<p>This algorithm differs slightly from the published algorithm.
The psuedo code is shown below.</p>
<pre class="literal-block">
v = highkey of R
u = highkey of Q
Unlink(P, Q, R) {
  upgrade-latch(P);
  delete the index record (u, Q.pageno);
  change the index record (v, R.pageno) to (v, Q.pageno);
  lsn = log(&lt;unlink, P, Q.pageno, R.pageno&gt;);
  P.pageLsn = lsn;
  unfix(P);
}
</pre>
</div>
<div class="section" id="redistribute-keys-operation">
<h3><a class="toc-backref" href="#id151">Redistribute Keys Operation</a></h3>
<p>This algorithm differs from the published algorithm. It
moves one key from the overpopulated node to the sibling node,
rather than evenly redistributing the keys across the two
nodes.</p>
<p>The Redistribute Key operation is logged using a Multi-Page
redo only log record.</p>
</div>
<div class="section" id="increase-tree-height-operation">
<h3><a class="toc-backref" href="#id152">Increase Tree Height Operation</a></h3>
<p>This differs from the published algorithm in following ways:</p>
<ol class="arabic simple">
<li>Page allocation is logged as redo-undo.</li>
<li>Space map page latch is released prior to any other exclusive latch.</li>
<li>The Increase Tree Height operatopn is logged as Muli Page
Compensation record, with undoNextLsn set to the LSN prior to the
page allocation log record.</li>
</ol>
<p>There is also no need to format the new page as pages are formatted
when they are first created.</p>
</div>
<div class="section" id="decrease-tree-height-operation">
<h3><a class="toc-backref" href="#id153">Decrease Tree Height Operation</a></h3>
<p>This differs from the published algorithm.</p>
<p>To increase concurrency, the  space map page update is logged after the
SMO as a separate redo only action. This improves concurrency because
the space map page latch is not held exclusively during the SMO. However,
it has the disadvantage that if the SMO survives a system crash, and the
log for the space map page updates does not survive,
then the page will remain allocated on the space map, even though it is no
longer in use. It is posible to identify deallocated pages by checking
the page flags for the BTreeNode but this is not implemented.</p>
<p>The Decrease Tree Height Operation is logged as Multi Page Redo only
log record.</p>
</div>
<div class="section" id="index-scans">
<h3><a class="toc-backref" href="#id154">Index Scans</a></h3>
<p>The published algorithm only considers the SERIALIZATION lock isolation
mode, but the implementation supports other lock modes. There are
differences in when and where locks are acquired and released under
various modes.</p>
</div>
<div class="section" id="simplified-algorithm-for-scans">
<h3><a class="toc-backref" href="#id155">Simplified Algorithm for Scans</a></h3>
<p>The published algorithm has a complex fetch and fetchnext logic,
and attempts to handle both &gt; and &gt;= operators. The implementation
is simpler.</p>
</div>
<div class="section" id="simpler-page-modification-checks">
<h3><a class="toc-backref" href="#id156">Simpler page modification checks</a></h3>
<p>The implementation uses a simpler check to determine whether the
page has changed since last it was latched. This may cause unnecessary
traversals from root node.</p>
</div>
<div class="section" id="b-tree-index-is-a-secondary-structure">
<h3><a class="toc-backref" href="#id157">B-Tree index is a secondary structure</a></h3>
<p>Unlike the published algorithm, where the B-Tree index holds the
data in the leaf nodes, the implementation stores Locations of
tuple data.</p>
</div>
</div>
</div>
<div class="section" id="tuple-manager">
<h1><a class="toc-backref" href="#id158">Tuple Manager</a></h1>
<div class="section" id="overview-of-tuple-manager">
<h2><a class="toc-backref" href="#id159">Overview of Tuple Manager</a></h2>
<p>The Tuple Manager module provides a low-level interface for
managing persistence of table rows. It is low-level in the sense that
this module has no knowledge of what is contained in a table row.
I use the term tuple instead of table row, but even this is not
the right term, as a tuple means a collection of attributes.</p>
<p>To the Tuple Manager, tuples are just blobs of data that can span
multiple pages. When a tuple is inserted for the first time, it
is assigned a unique Location, which is really an abstraction of
the ROWID concept in other databases. The Tuple Manager module
implements the Location interface, but other modules do not need
to know anything about the internal structure of these objects.</p>
<p>Like B-Tree indexes, tuples are stored in containers. A container
that is specialized for storing tuples is called a Tuple Container.
By design, only one type of tuple may be stored in a particular
container. In a higher level module, a tuple can be mapped to a
table row, and the container to a table.</p>
<p>The interface of Tuple Manager is made generic by ensuring that it
knows very little about tuples. Unfortunately, this means that
tuple updates cannot be handled efficiently, specially with regards
to logging, as the contents of the both before and after images of
the tuple must be logged. A possible optimisation would be to use
some form of binary diff algorithm to generate a change vector,
and store the change vector only in the log record.</p>
</div>
<div class="section" id="design-decisions">
<h2><a class="toc-backref" href="#id160">Design Decisions</a></h2>
<p>Some of the implementation decisions are given below:</p>
<div class="section" id="tuple-inserts">
<h3><a class="toc-backref" href="#id161">Tuple Inserts</a></h3>
<p>Tuple inserts are done in two stages. In the first stage,
a new Location is allocated and locked exclusively. Also, the
tuple data is inserted into the first page that will be used by the
tuple. The rest of the tuple data is inserted in the second stage. The
rationale for splitting the insert into two stages is to allow
the client to perform other operations in between, such as creating
Index keys.</p>
</div>
<div class="section" id="tuple-segmentation">
<h3><a class="toc-backref" href="#id162">Tuple Segmentation</a></h3>
<p>If a tuple is too large to fit into one page, it is broken into
chunks of <tt class="docutils literal"><span class="pre">TupleManagerImpl.TupleSegment</span></tt>. Each segment is inserted
into a page, and the segments are linked together in a singly linked
list. Since the segments are inserted in order, in the first pass the links
are not set, and the implementation has to revisit all the pages and update
the links between the segments. The last segment/page does not require an update.</p>
<p>At the time of insert, the implementation tries to allocate as much space
as possible on each page. When a page is visited, an attempt is made to reclaim
any deleted segments within the page.</p>
</div>
<div class="section" id="tuple-deletes">
<h3><a class="toc-backref" href="#id163">Tuple Deletes</a></h3>
<p>Deletes are logical, ie, the Tuple Segments are marked with a logical
delete flag. Space Map information is updated immediately, however. During deletes,
the links between the segments of a tuple are broken. This is because the
link is reused to store the tuple's Location. Thus, it is possible to determine
the Location of a tuple from any of the deleted segments. This is important
because the tuple reclamation logic uses locking to determine whether a logically
deleted tuple can be physically removed.</p>
<p>If the delete is undone, the links are restored.</p>
</div>
<div class="section" id="tuple-updates">
<h3><a class="toc-backref" href="#id164">Tuple Updates</a></h3>
<p>When tuples are updated, existing segments are updated with new data. If the new
tuple is longer than the old tuple, then additional segments are added. The
<tt class="docutils literal"><span class="pre">TupleInserter#completeInsert()</span></tt> interface is reused for this purpose. No attempt is
made to change the size of existing segments, even if there is additional space available in
the page. This is to keep the algorithm simple. Also, segments are never released,
even if the new tuple has become smaller and does not occupy all the segments.</p>
<p>Note that due to the way this is implemented, more than one segment of the same
tuple can end up in the same page.</p>
<p>Since the structure of the tuple is opaque to this module, updates are not
very efficiently handled. Current implementation logs the full before and after images
of the tuple being updated. In future, this needs to be made more efficient by using some
form of binary diff algorithm.</p>
</div>
<div class="section" id="space-reclamation">
<h3><a class="toc-backref" href="#id165">Space Reclamation</a></h3>
<p>Space used by deleted tuples is reclaimed when some other transaction visits
the affected page and tries to use the space. Locking is used to determine whether
the delete was committed. The actual physical removal of the tuple segments are
logged. Note that this method of determining whether a segment can be released is
conservative and sometimes results in segments being retained even when they are no
longer required. Why this happens will become clear with an example. Suppose that
a tuple that has 4 segments is deleted. Each segment is marked deleted. Now, some
transaction creates a new tuple, reusing the Location of the deleted tuple. However,
the new tuple may not reuse all the segments used by the old tuple, in fact, only
the first segment is guaranteed to be reused. As a result of the tuple insert, the
Location gets exclusively locked. If this transaction or any other transaction
encounters the remaining segments that are marked deleted, the reclamation logic will
incorrectly assume that the delete is still uncommitted, because the lock on the
location will fail. The segments wil get eventually reused, when the transaction
that locked the tuple commits.</p>
</div>
<div class="section" id="tuple-segment-structure">
<h3><a class="toc-backref" href="#id166">Tuple Segment Structure</a></h3>
<p>Each Tuple segment contains three fields.</p>
<dl class="docutils">
<dt>nextPageNumber</dt>
<dd>Used only in segmented tuples. Normally, points to the location of
next segment. If a tuple is deleted, this is updated to the page
number of the first segment.</dd>
<dt>nextSlotNumber</dt>
<dd>Used only in segmented tuples. Normally, points to the location of
next segment. If a tuple is deleted, this is updated to the slot
number of the first segment.</dd>
<dt>data</dt>
<dd>Data in this segment.</dd>
</dl>
</div>
<div class="section" id="free-space-information">
<h3><a class="toc-backref" href="#id167">Free Space Information</a></h3>
<p>Both BTrees and Tuple Containers need free space management. By
free space management we mean the process of identifying pages
where new data can go. In the case of B-Trees, SimpleDBM uses
space map pages that use one bit per page. This is okay, because in
a BTree, a page is either allocated or not.</p>
<p>In case of Tuple Containers, I am using space map pages that use
two bits to store the space information for a single page. This means
that we can track the following states: full (3), two-thirds full
(2), one-third full (1), and empty (0). Initially pages start out
empty, but when they are used, their status changes as required.</p>
<p>There are a couple of issues related to space management that
merit discussion. Unfortunately, there are very few papers that
go into all the details. I have found the following papers very
useful:</p>
<blockquote>
<p>C.Mohan and D.Haderle. Algorithms for Flexible Space Management
in Transaction Systems Supporting Fine-Granularity Locking.
In Proceedings of the International Conference on Extending
Database Technology, March 1994.</p>
<p>Mark L.McAuliffe, Michael J. Carey and Marvin H. Solomon. Towards
Effective and Efficient Free Space Management. ACM SIGMOD Record.
Proceedings of the 1996 ACM SIGMOD international conference on
Management of Data, June 1996.</p>
</blockquote>
<p>The first issue is how to handle deletes. There are two options.</p>
<p>The first option is to delete a tuple physically and update space
map page to reflect the change. However, this poses the problem that
if the transaction aborts and the tuple needs to be restored,
then the restore will fail if some other transaction uses up the
released space in the meantime. To prevent this, some extra
information needs to be stored in the page to indicate that
although the tuple has been deleted, its space is reserved, and
cannot be used by any other transaction. One possible approach is
to store the transaction id and the amount of space reserved using
the space previously occupied by the tuple. If the tuple occupied
more than one page, then space must be reserved on all affected pages,
since otherwise, when the tuple is to be restored, the pages
may no longer have space to hold the tuple data. If logical undo
is implemented, then it is possible to avoid reserving space in
pages other than the first page, because a logical undo will
allow new pages to be commissioned if necessary to accomodate
the restored tuple. Since the tuple's unique id (Location) is bound
to the first page, this page must always have space available
for the tuple to be restored.</p>
<p>If as suggested above, the space map information is updated as
soon as the tuple is deleted, then other transactions looking
for free space may end up visiting the pages that have been affected
by the tuple delete. However, those transactions may discover
when they access the page, that space is not actually available.
As a solution to this problem, the space map page update
could be deferred until the tuple delete is known to have
been committed. However, this would be inefficient, as the
transaction that performs the delete will have to visit all pages
affected by deleted tuples at commit time, and update the
free space map information for these pages.</p>
<p>The space map update could also be delegated to the next
transaction that needs the space. The problem with this is that
if the page remains marked as fully allocated, then no other
transaction will visit that page unless the tuples on the
page need to be updated. There is the risk that the tuple
space will never be reclaimed.</p>
<p>The problem of unnecessary visits to a page containing reserved
space can be avoided by techniques described in [2]. This
involves maintaining a cache of recently used pages and avoiding
scanning of the free space map as long as there is candidate
page available in the cache. When a page is affected by
a tuple delete, it is added to the cache provided that its
total free space, including the space reserved for deleted tuple,
is greater than the fullest page in the cache. If a transaction
visits such a page and is unable to use the reserved space,
it removes the page from the cache.</p>
<p>In summary then, the preferred option appears to be to update
the space map information as soon as the tuple is deleted.</p>
<p>Physically deleting tuples affects the amount of logging
that must be performed. Since the tuple's data is removed,
the log must contain the entire contents of the deleted tuple.
Similarly, when undoing the delete, the Compensation log
record must again contain the full content of the tuple.
Thus the tuple data gets logged twice potentially,
once when the delete occurs, and again if the transaction
aborts.</p>
<p>This brings us to the second option, which is to use
logical deletes. In this solution, the tuple remains as
is, but is marked as deleted. No space reservation is
needed, as the tuple still exists. The space map
information is updated as before, that is, at the time
of tuple being deleted. Using logical deletes makes
undo of such deletes a simple matter of resetting
the deleted flag. Logging overhead is substantially
reduced.</p>
<p>With logical deletes, however, none of the space can
be released prior to the transaction commit. In contrast,
with physical deletes, if logical undo is implemented,
at least some of the space can be immediately released.</p>
<p>Whether logical or physical deletes are used, in both
cases, we still have the issue of how to inform other
transactions that the tuple space is still needed. In both
cases, the solution is the same. The Lock Manager can
be used to ascertain whether the deleted tuple is still
locked. If not, then the transaction can infer that tuple
delete has been committed. The Lock Manager solution
works even if the ID of the transaction that deleted the
tuple is unknown, as it relies upon the tuple's Location
only. If each tuple is tagged with the ID of the last
transaction that updated the tuple, then it would be
possible to directly query the transaction table for
the status of the transaction. However in this case,
the system would have to maintain the status of all
transactions, even those that have committed or aborted.</p>
<p>SimpleDBM maintains the status of only active transactions,
and also does not tag tuples with the IDs of transactions.
Hence, it is appropriate to use the Lock Manager solution
in SimpleDBM.</p>
</div>
</div>
</div>
</div>
</body>
</html>
